{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d14ad952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import train_autoencoder\n",
    "import autoencoder\n",
    "import run\n",
    "import train_CGAN\n",
    "import CGAN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import importlib\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aaab6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading MIDI files and preparing data: 100%|██████████████████████████████████| 1276/1276 [10:11<00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 3667 total chunk overflows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(run)\n",
    "importlib.reload(autoencoder)\n",
    "importlib.reload(train_autoencoder)\n",
    "importlib.reload(utils)\n",
    "\n",
    "events, annotation, metadata = run.ReadMIDI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "224ddf81",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(train_autoencoder)\n\u001b[1;32m      4\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(utils)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainAE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Python/TimeStepMusic/python/run.py:74\u001b[0m, in \u001b[0;36mTrainAE\u001b[0;34m(events, annotation, metadata)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mTrainAE\u001b[39m(events, annotation, metadata):\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m#prepares datasets and trains the autoencoder\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(HOME_PATH, MODELS_FOLDER)\n\u001b[0;32m---> 74\u001b[0m     ae_train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_autoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAutoEncoderDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mCHUNK_LENGTH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATA_TYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mAUG_TYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     ae_valid_dataset \u001b[38;5;241m=\u001b[39m train_autoencoder\u001b[38;5;241m.\u001b[39mAutoEncoderDataset(events, annotation, metadata, \n\u001b[1;32m     78\u001b[0m                                                             CHUNK_LENGTH, DATA_TYPE, \n\u001b[1;32m     79\u001b[0m                                                             AUG_TYPE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     81\u001b[0m     ae_model \u001b[38;5;241m=\u001b[39m autoencoder\u001b[38;5;241m.\u001b[39mAutoEncoder(data_type\u001b[38;5;241m=\u001b[39mDATA_TYPE, hidden_dim\u001b[38;5;241m=\u001b[39mAE_LATENT_DIM, \n\u001b[1;32m     82\u001b[0m                                        max_n\u001b[38;5;241m=\u001b[39mMAX_CHUNK_SIZE)\n",
      "File \u001b[0;32m~/Documents/Python/TimeStepMusic/python/train_autoencoder.py:57\u001b[0m, in \u001b[0;36mAutoEncoderDataset.__init__\u001b[0;34m(self, events, annotation, metadata, chunk_length, data_type, aug_type, split)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#internal annotation should reference internal events indices\u001b[39;00m\n\u001b[1;32m     53\u001b[0m inverse_events_indices \u001b[38;5;241m=\u001b[39m {external:internal \u001b[38;5;28;01mfor\u001b[39;00m internal, external \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m     54\u001b[0m                           \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent_indices)}\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mannotation \u001b[38;5;241m=\u001b[39m {idx:(annotation[idx][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     58\u001b[0m                         annotation[idx][\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     59\u001b[0m                         inverse_events_indices[annotation[idx][\u001b[38;5;241m2\u001b[39m]])\n\u001b[1;32m     60\u001b[0m                         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_indices}\n",
      "File \u001b[0;32m~/Documents/Python/TimeStepMusic/python/train_autoencoder.py:57\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#internal annotation should reference internal events indices\u001b[39;00m\n\u001b[1;32m     53\u001b[0m inverse_events_indices \u001b[38;5;241m=\u001b[39m {external:internal \u001b[38;5;28;01mfor\u001b[39;00m internal, external \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m     54\u001b[0m                           \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent_indices)}\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mannotation \u001b[38;5;241m=\u001b[39m {idx:(annotation[idx][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     58\u001b[0m                         annotation[idx][\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     59\u001b[0m                         inverse_events_indices[annotation[idx][\u001b[38;5;241m2\u001b[39m]])\n\u001b[1;32m     60\u001b[0m                         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_indices}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "importlib.reload(run)\n",
    "importlib.reload(autoencoder)\n",
    "importlib.reload(train_autoencoder)\n",
    "importlib.reload(utils)\n",
    "\n",
    "run.TrainAE(events, annotation, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e6c0ef0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data...\n",
      "Track 1062\n",
      "[[   34    54   993    56]\n",
      " [   30    58  1056    52]\n",
      " [   27    61  1039    54]\n",
      " [   51   170   577    77]\n",
      " [   88   157    15    50]\n",
      " [   88   172   108    78]\n",
      " [   88    88   581   124]\n",
      " [   54   147    25    69]\n",
      " [   53    51    75    85]\n",
      " [   34    61   901    69]\n",
      " [   26    65   886    65]\n",
      " [   29    65   996    63]\n",
      " [   46     3   456    85]\n",
      " [   88    42    46    81]\n",
      " [   88    88    16    18]\n",
      " [   88   104    46    79]\n",
      " [   88   150   813   125]\n",
      " [   46    95    57    70]\n",
      " [   48   158    56    76]\n",
      " [   50     2    62    69]\n",
      " [   51    51    46    71]\n",
      " [   53    77    34    74]\n",
      " [   55   153    51    92]\n",
      " [   34   161   882    81]\n",
      " [   31   163   983    73]\n",
      " [   25   164   912    71]\n",
      " [   27   164   964    69]\n",
      " [   88     3    31    80]\n",
      " [   55   108   539    91]\n",
      " [   88    30    14    45]\n",
      " [   88    44    15    20]\n",
      " [   88    59    61    80]\n",
      " [   88   120   692   126]\n",
      " [   58    76    35    82]\n",
      " [   56   183   121    94]\n",
      " [   32     6   869    81]\n",
      " [   27     7   909    71]\n",
      " [   24     8   858    69]\n",
      " [   88    44    31    85]\n",
      " [   44   148   270    92]\n",
      " [   88    75    38    59]\n",
      " [   88   113    46    83]\n",
      " [   88   159   700   126]\n",
      " [   51    24    46    73]\n",
      " [   53    72    56    74]\n",
      " [   55   114    47    68]\n",
      " [   56   154   153    73]\n",
      " [   30    50   845    78]\n",
      " [   33    51   787    90]\n",
      " [   57    54     1    58]\n",
      " [   27    58   833    73]\n",
      " [   23    62   815    70]\n",
      " [   88    91    52    84]\n",
      " [   45   173   235    94]\n",
      " [   88    85    15    20]\n",
      " [   88   100    16    64]\n",
      " [   88   116    29    82]\n",
      " [   88   145   633   126]\n",
      " [   51     0    55    65]\n",
      " [   53    49    54    66]\n",
      " [   54    82    45    68]\n",
      " [   57   110   110    75]\n",
      " [   58   181    63   100]\n",
      " [   34     3    50    87]\n",
      " [   22     4    83    78]\n",
      " [   30     5    71    81]\n",
      " [   27    12    63    70]\n",
      " [   26    69    53     4]\n",
      " [   47    98   953    92]\n",
      " [   51    99   959    82]\n",
      " [   56    99   964    77]\n",
      " [   32   100   931    90]\n",
      " [   59   100   951    88]\n",
      " [   23   104   982    73]\n",
      " [   27   107   954    73]\n",
      " [   20   109   967    76]\n",
      " [   88    32    90    78]\n",
      " [   88   122   799   126]\n",
      " [   90   123    15    13]\n",
      " [   90   138    15    38]\n",
      " [   90   153    16    77]\n",
      " [   88   153    31    86]\n",
      " [   90   169 33802   127]\n",
      " [   47   114    28    64]\n",
      " [   23   115    36    52]\n",
      " [   20    39    51    65]\n",
      " [   44    39    44    71]\n",
      " [   46   143    66    58]\n",
      " [   22   150    61    52]\n",
      " [   39    85    79    55]\n",
      " [   27    89    53    48]\n",
      " [   22    28    65    54]\n",
      " [   15   155    76    44]\n",
      " [   34    89    44    63]\n",
      " [   39     8    80    66]\n",
      " [   42   112    30    62]\n",
      " [   46    26    53    75]\n",
      " [   51   139    55    68]\n",
      " [   54    42    37    68]\n",
      " [   58   146    31    66]]\n",
      "tensor([[     0.000,     -0.429,      0.818,     -0.438,      0.986,     -0.125],\n",
      "        [     0.000,     -0.429,      0.091,     -0.396,      0.988,     -0.188],\n",
      "        [     0.000,     -0.429,     -0.455,     -0.365,      0.987,     -0.156],\n",
      "        [     0.000,      0.143,     -0.455,      0.771,      0.956,      0.203],\n",
      "        [     0.333,      1.000,     -0.273,      0.635,      0.063,     -0.219],\n",
      "        [     0.333,      1.000,     -0.273,      0.792,      0.587,      0.219],\n",
      "        [     0.333,      1.000,     -0.273,     -0.083,      0.957,      0.938],\n",
      "        [     0.000,      0.143,      0.091,      0.531,      0.140,      0.078],\n",
      "        [     0.000,      0.143,     -0.091,     -0.469,      0.459,      0.328],\n",
      "        [     0.000,     -0.429,      0.818,     -0.365,      0.982,      0.078],\n",
      "        [     0.000,     -0.429,     -0.636,     -0.323,      0.982,      0.016],\n",
      "        [     0.000,     -0.429,     -0.091,     -0.323,      0.986,     -0.016],\n",
      "        [     0.000,     -0.143,      0.818,     -0.969,      0.933,      0.328],\n",
      "        [     0.333,      1.000,     -0.273,     -0.562,      0.295,      0.266],\n",
      "        [     0.333,      1.000,     -0.273,     -0.083,      0.070,     -0.719],\n",
      "        [     0.333,      1.000,     -0.273,      0.083,      0.295,      0.234],\n",
      "        [     0.333,      1.000,     -0.273,      0.562,      0.978,      0.953],\n",
      "        [     0.000,     -0.143,      0.818,     -0.010,      0.364,      0.094],\n",
      "        [     0.000,      0.143,     -1.000,      0.646,      0.358,      0.188],\n",
      "        [     0.000,      0.143,     -0.636,     -0.979,      0.393,      0.078],\n",
      "        [     0.000,      0.143,     -0.455,     -0.469,      0.295,      0.109],\n",
      "        [     0.000,      0.143,     -0.091,     -0.198,      0.210,      0.156],\n",
      "        [     0.000,      0.143,      0.273,      0.594,      0.328,      0.438],\n",
      "        [     0.000,     -0.429,      0.818,      0.677,      0.981,      0.266],\n",
      "        [     0.000,     -0.429,      0.273,      0.698,      0.985,      0.141],\n",
      "        [     0.000,     -0.429,     -0.818,      0.708,      0.983,      0.109],\n",
      "        [     0.000,     -0.429,     -0.455,      0.708,      0.985,      0.078],\n",
      "        [     0.333,      1.000,     -0.273,     -0.969,      0.187,      0.250],\n",
      "        [     0.000,      0.143,      0.273,      0.125,      0.950,      0.422],\n",
      "        [     0.333,      1.000,     -0.273,     -0.688,      0.056,     -0.297],\n",
      "        [     0.333,      1.000,     -0.273,     -0.542,      0.063,     -0.688],\n",
      "        [     0.333,      1.000,     -0.273,     -0.385,      0.387,      0.250],\n",
      "        [     0.333,      1.000,     -0.273,      0.250,      0.969,      0.969],\n",
      "        [     0.000,      0.143,      0.818,     -0.208,      0.218,      0.281],\n",
      "        [     0.000,      0.143,      0.455,      0.906,      0.626,      0.469],\n",
      "        [     0.000,     -0.429,      0.455,     -0.938,      0.981,      0.266],\n",
      "        [     0.000,     -0.429,     -0.455,     -0.927,      0.983,      0.109],\n",
      "        [     0.000,     -0.429,     -1.000,     -0.917,      0.980,      0.078],\n",
      "        [     0.333,      1.000,     -0.273,     -0.542,      0.187,      0.328],\n",
      "        [     0.000,     -0.143,      0.455,      0.542,      0.849,      0.438],\n",
      "        [     0.333,      1.000,     -0.273,     -0.219,      0.240,     -0.078],\n",
      "        [     0.333,      1.000,     -0.273,      0.177,      0.295,      0.297],\n",
      "        [     0.333,      1.000,     -0.273,      0.656,      0.970,      0.969],\n",
      "        [     0.000,      0.143,     -0.455,     -0.750,      0.295,      0.141],\n",
      "        [     0.000,      0.143,     -0.091,     -0.250,      0.358,      0.156],\n",
      "        [     0.000,      0.143,      0.273,      0.188,      0.302,      0.062],\n",
      "        [     0.000,      0.143,      0.455,      0.604,      0.702,      0.141],\n",
      "        [     0.000,     -0.429,      0.091,     -0.479,      0.980,      0.219],\n",
      "        [     0.000,     -0.429,      0.636,     -0.469,      0.976,      0.406],\n",
      "        [     0.000,      0.143,      0.636,     -0.438,      0.000,     -0.094],\n",
      "        [     0.000,     -0.429,     -0.455,     -0.396,      0.979,      0.141],\n",
      "        [     0.000,     -0.714,      1.000,     -0.354,      0.978,      0.094],\n",
      "        [     0.333,      1.000,     -0.273,     -0.052,      0.334,      0.312],\n",
      "        [     0.000,     -0.143,      0.636,      0.802,      0.819,      0.469],\n",
      "        [     0.333,      1.000,     -0.273,     -0.115,      0.063,     -0.688],\n",
      "        [     0.333,      1.000,     -0.273,      0.042,      0.070,      0.000],\n",
      "        [     0.333,      1.000,     -0.273,      0.208,      0.172,      0.281],\n",
      "        [     0.333,      1.000,     -0.273,      0.510,      0.963,      0.969],\n",
      "        [     0.000,      0.143,     -0.455,     -1.000,      0.352,      0.016],\n",
      "        [     0.000,      0.143,     -0.091,     -0.490,      0.346,      0.031],\n",
      "        [     0.000,      0.143,      0.091,     -0.146,      0.289,      0.062],\n",
      "        [     0.000,      0.143,      0.636,      0.146,      0.593,      0.172],\n",
      "        [     0.000,      0.143,      0.818,      0.885,      0.398,      0.562],\n",
      "        [     0.000,     -0.429,      0.818,     -0.969,      0.321,      0.359],\n",
      "        [     0.000,     -0.714,      0.818,     -0.958,      0.494,      0.219],\n",
      "        [     0.000,     -0.429,      0.091,     -0.948,      0.439,      0.266],\n",
      "        [     0.000,     -0.429,     -0.455,     -0.875,      0.398,      0.094],\n",
      "        [     0.000,     -0.429,     -0.636,     -0.281,      0.340,     -0.938],\n",
      "        [     0.000,     -0.143,      1.000,      0.021,      0.984,      0.438],\n",
      "        [     0.000,      0.143,     -0.455,      0.031,      0.985,      0.281],\n",
      "        [     0.000,      0.143,      0.455,      0.031,      0.985,      0.203],\n",
      "        [     0.000,     -0.429,      0.455,      0.042,      0.984,      0.406],\n",
      "        [     0.000,      0.143,      1.000,      0.042,      0.984,      0.375],\n",
      "        [     0.000,     -0.714,      1.000,      0.083,      0.985,      0.141],\n",
      "        [     0.000,     -0.429,     -0.455,      0.115,      0.984,      0.141],\n",
      "        [     0.000,     -0.714,      0.455,      0.135,      0.985,      0.188],\n",
      "        [     0.333,      1.000,     -0.273,     -0.667,      0.523,      0.219],\n",
      "        [     0.333,      1.000,     -0.273,      0.271,      0.977,      0.969],\n",
      "        [     1.000,      1.000,      0.091,      0.281,      0.063,     -0.797],\n",
      "        [     1.000,      1.000,      0.091,      0.438,      0.063,     -0.406],\n",
      "        [     1.000,      1.000,      0.091,      0.594,      0.070,      0.203],\n",
      "        [     0.333,      1.000,     -0.273,      0.594,      0.187,      0.344],\n",
      "        [     1.000,      1.000,      0.091,      0.760,      1.000,      0.984],\n",
      "        [     0.000,     -0.143,      1.000,      0.188,      0.164,      0.000],\n",
      "        [     0.000,     -0.714,      1.000,      0.198,      0.225,     -0.188],\n",
      "        [     0.000,     -0.714,      0.455,     -0.594,      0.328,      0.016],\n",
      "        [     0.000,     -0.143,      0.455,     -0.594,      0.282,      0.109],\n",
      "        [     0.000,     -0.143,      0.818,      0.490,      0.414,     -0.094],\n",
      "        [     0.000,     -0.714,      0.818,      0.562,      0.387,     -0.188],\n",
      "        [     0.000,     -0.143,     -0.455,     -0.115,      0.477,     -0.141],\n",
      "        [     0.000,     -0.429,     -0.455,     -0.073,      0.340,     -0.250],\n",
      "        [     0.000,     -0.714,      0.818,     -0.708,      0.409,     -0.156],\n",
      "        [     0.000,     -0.714,     -0.455,      0.615,      0.463,     -0.312],\n",
      "        [     0.000,     -0.429,      0.818,     -0.073,      0.282,     -0.016],\n",
      "        [     0.000,     -0.143,     -0.455,     -0.917,      0.481,      0.031],\n",
      "        [     0.000,     -0.143,      0.091,      0.167,      0.180,     -0.031],\n",
      "        [     0.000,     -0.143,      0.818,     -0.729,      0.340,      0.172],\n",
      "        [     0.000,      0.143,     -0.455,      0.448,      0.352,      0.062],\n",
      "        [     0.000,      0.143,      0.091,     -0.562,      0.232,      0.062],\n",
      "        [     0.000,      0.143,      0.818,      0.521,      0.187,      0.031]])\n",
      "tensor([[    -0.020,     -0.440,      0.818,     -0.418,      1.024,     -0.149],\n",
      "        [    -0.009,     -0.444,      0.095,     -0.387,      0.951,     -0.154],\n",
      "        [    -0.002,     -0.443,     -0.450,     -0.401,      0.863,     -0.195],\n",
      "        [    -0.004,      0.152,     -0.448,      0.811,      0.789,      0.096],\n",
      "        [     0.362,      1.020,     -0.269,      0.847,      0.451,      0.100],\n",
      "        [     0.336,      0.988,     -0.273,      0.682,      0.381,      0.009],\n",
      "        [     0.352,      0.986,     -0.279,     -0.023,      0.865,      0.643],\n",
      "        [    -0.003,      0.170,      0.091,      0.553,      0.387,      0.042],\n",
      "        [    -0.016,     -0.439,      0.814,     -0.338,      1.013,      0.096],\n",
      "        [    -0.001,     -0.446,     -0.098,     -0.323,      0.939,      0.049],\n",
      "        [    -0.003,     -0.441,     -0.638,     -0.356,      0.846,     -0.030],\n",
      "        [    -0.016,      0.171,     -0.120,     -0.609,      0.761,      0.169],\n",
      "        [     0.009,     -0.138,      0.785,     -0.899,      0.702,      0.201],\n",
      "        [     0.335,      1.026,     -0.291,      0.548,      0.656,      0.484],\n",
      "        [     0.294,      0.977,     -0.268,      0.140,      0.602,      0.398],\n",
      "        [     0.303,      1.009,     -0.284,     -0.288,      0.517,      0.314],\n",
      "        [     0.303,      1.005,     -0.277,     -0.530,      0.451,      0.236],\n",
      "        [     0.002,     -0.141,      0.842,     -0.005,      0.427,      0.101],\n",
      "        [    -0.008,      0.156,     -1.005,      0.653,      0.403,      0.096],\n",
      "        [    -0.022,     -0.413,      0.860,      0.708,      1.058,      0.288],\n",
      "        [    -0.026,     -0.472,      0.293,      0.737,      0.984,      0.218],\n",
      "        [     0.007,     -0.478,     -0.452,      0.765,      0.923,      0.186],\n",
      "        [    -0.002,     -0.440,     -0.839,      0.573,      0.857,      0.138],\n",
      "        [    -0.007,      0.246,      0.166,     -0.129,      0.663,      0.223],\n",
      "        [     0.003,      0.138,     -0.135,     -0.296,      0.634,      0.219],\n",
      "        [    -0.016,      0.092,     -0.486,     -0.459,      0.380,      0.090],\n",
      "        [     0.038,      0.206,     -0.274,     -0.395,      0.409,      0.081],\n",
      "        [     0.319,      0.956,     -0.292,     -0.940,      0.468,      0.273],\n",
      "        [    -0.016,      0.175,      0.285,      0.179,      0.789,      0.225],\n",
      "        [     0.375,      1.029,     -0.288,      0.249,      0.525,      0.349],\n",
      "        [     0.324,      0.999,     -0.288,     -0.393,      0.452,      0.237],\n",
      "        [     0.282,      0.951,     -0.272,     -0.523,      0.381,      0.137],\n",
      "        [     0.321,      1.003,     -0.249,     -0.760,      0.344,      0.101],\n",
      "        [     0.007,      0.167,      0.463,      0.918,      0.490,      0.351],\n",
      "        [    -0.005,      0.113,      0.839,     -0.080,      0.464,      0.273],\n",
      "        [    -0.015,     -0.452,      0.432,     -0.902,      0.965,      0.219],\n",
      "        [     0.004,     -0.450,     -0.453,     -0.889,      0.895,      0.143],\n",
      "        [    -0.002,     -0.434,     -0.977,     -0.945,      0.793,      0.045],\n",
      "        [     0.307,      1.002,     -0.257,     -0.556,      0.691,      0.403],\n",
      "        [    -0.012,     -0.106,      0.466,      0.590,      0.726,      0.184],\n",
      "        [     0.362,      1.036,     -0.275,      0.670,      0.647,      0.638],\n",
      "        [     0.326,      1.007,     -0.276,      0.203,      0.551,      0.481],\n",
      "        [     0.305,      0.979,     -0.263,     -0.149,      0.453,      0.325],\n",
      "        [     0.001,      0.145,      0.470,      0.620,      0.477,      0.178],\n",
      "        [     0.007,      0.138,      0.274,      0.225,      0.452,      0.133],\n",
      "        [     0.002,      0.168,     -0.102,     -0.329,      0.444,      0.090],\n",
      "        [    -0.002,      0.151,     -0.459,     -0.701,      0.453,      0.078],\n",
      "        [    -0.006,     -0.712,      0.987,     -0.314,      0.956,      0.146],\n",
      "        [    -0.002,     -0.416,      0.628,     -0.477,      0.923,      0.245],\n",
      "        [    -0.004,     -0.442,      0.121,     -0.374,      0.817,      0.154],\n",
      "        [    -0.004,      0.156,      0.624,     -0.536,      0.718,      0.318],\n",
      "        [    -0.018,     -0.428,     -0.477,     -0.544,      0.714,      0.102],\n",
      "        [     0.306,      0.979,     -0.214,      0.144,      0.613,      0.382],\n",
      "        [    -0.007,     -0.099,      0.628,      0.835,      0.708,      0.213],\n",
      "        [     0.370,      1.020,     -0.280,      0.510,      0.455,      0.458],\n",
      "        [     0.314,      1.001,     -0.286,      0.183,      0.391,      0.344],\n",
      "        [     0.304,      0.963,     -0.259,      0.119,      0.329,      0.226],\n",
      "        [     0.309,      0.997,     -0.271,     -0.248,      0.293,      0.142],\n",
      "        [     0.002,      0.166,      0.840,      0.929,      0.415,      0.377],\n",
      "        [     0.003,      0.124,      0.642,      0.165,      0.410,      0.303],\n",
      "        [    -0.006,      0.131,      0.089,     -0.121,      0.409,      0.244],\n",
      "        [     0.002,      0.170,     -0.105,     -0.617,      0.423,      0.239],\n",
      "        [    -0.002,      0.137,     -0.453,     -0.880,      0.408,      0.163],\n",
      "        [    -0.004,     -0.706,      0.815,     -0.851,      0.350,     -0.033],\n",
      "        [    -0.002,     -0.432,      0.817,     -0.891,      0.393,      0.094],\n",
      "        [     0.004,     -0.505,     -0.654,     -0.247,      0.387,     -0.017],\n",
      "        [     0.000,     -0.408,      0.075,     -0.954,      0.451,      0.110],\n",
      "        [    -0.006,     -0.417,     -0.459,     -0.880,      0.445,      0.051],\n",
      "        [    -0.001,     -0.713,      1.033,      0.119,      1.237,      0.272],\n",
      "        [    -0.002,     -0.711,      0.443,      0.035,      1.185,      0.285],\n",
      "        [     0.004,     -0.159,      1.022,      0.275,      1.072,      0.449],\n",
      "        [    -0.005,     -0.387,      0.412,     -0.144,      0.903,      0.223],\n",
      "        [    -0.004,      0.165,      0.939,     -0.298,      0.749,      0.305],\n",
      "        [    -0.020,      0.142,      0.402,     -0.196,      0.698,      0.280],\n",
      "        [    -0.017,      0.084,     -0.202,     -0.348,      0.356,      0.128],\n",
      "        [     0.030,      0.215,     -0.033,     -0.087,      0.439,      0.125],\n",
      "        [     0.343,      1.025,     -0.289,      0.303,      0.843,      0.708],\n",
      "        [     0.303,      0.987,     -0.276,     -0.727,      0.711,      0.531],\n",
      "        [     0.971,      0.995,      0.082,      0.704,      0.452,      0.443],\n",
      "        [     0.315,      1.001,     -0.299,      0.407,      0.324,      0.341],\n",
      "        [     0.909,      1.003,      0.096,      0.663,      0.359,      0.242],\n",
      "        [     0.999,      1.027,      0.082,      0.284,      0.297,      0.067],\n",
      "        [     1.019,      1.058,      0.034,     -0.033,      0.270,     -0.025],\n",
      "        [     0.007,     -0.716,      0.995,      0.169,      0.262,     -0.223],\n",
      "        [    -0.014,     -0.137,      0.991,      0.156,      0.279,     -0.004],\n",
      "        [    -0.004,     -0.719,      0.463,     -0.612,      0.360,     -0.103],\n",
      "        [    -0.025,     -0.178,      0.468,     -0.568,      0.363,      0.095],\n",
      "        [     0.002,     -0.721,      0.816,      0.559,      0.429,     -0.242],\n",
      "        [    -0.014,     -0.144,      0.819,      0.498,      0.417,     -0.037],\n",
      "        [    -0.005,     -0.430,     -0.460,     -0.065,      0.461,     -0.227],\n",
      "        [    -0.013,     -0.156,     -0.468,     -0.096,      0.432,     -0.135],\n",
      "        [    -0.010,     -0.714,      0.826,     -0.760,      0.498,     -0.256],\n",
      "        [    -0.022,     -0.700,     -0.449,      0.645,      0.532,     -0.331],\n",
      "        [    -0.006,     -0.422,      0.824,     -0.106,      0.443,     -0.119],\n",
      "        [    -0.001,     -0.153,      0.098,      0.166,      0.383,      0.012],\n",
      "        [    -0.000,     -0.155,     -0.453,     -0.922,      0.372,     -0.045],\n",
      "        [    -0.000,     -0.140,      0.825,     -0.733,      0.404,      0.067],\n",
      "        [    -0.013,      0.145,     -0.480,      0.453,      0.387,      0.116],\n",
      "        [     0.019,      0.140,      0.822,      0.517,      0.293,      0.075],\n",
      "        [    -0.001,      0.137,      0.101,     -0.550,      0.294,      0.010]])\n",
      "[[   34   823 17747    54]\n",
      " [   30   826   544    54]\n",
      " [   27   825   288    51]\n",
      " [   51  1325   207    70]\n",
      " [   88  1521    73    70]\n",
      " [   88  1505    59    64]\n",
      " [   88  1629   292   105]\n",
      " [   54  2069    60    66]\n",
      " [   34  2175 17747    70]\n",
      " [   29  2176   479    67]\n",
      " [   26  2173   265    62]\n",
      " [   53  2149   187    74]\n",
      " [   46  2697   153    76]\n",
      " [   88  2836   132    94]\n",
      " [   88  2797   112    89]\n",
      " [   88  2756    88    84]\n",
      " [   88  2733    73    79]\n",
      " [   46  3359    68    70]\n",
      " [   48  3422    63    70]\n",
      " [   34  3620 17747    82]\n",
      " [   31  3622   949    77]\n",
      " [   27  3625   420    75]\n",
      " [   25  3607   280    72]\n",
      " [   54  3539   135    78]\n",
      " [   53  3523   123    78]\n",
      " [   51  3507    59    69]\n",
      " [   52  3514    65    69]\n",
      " [   88  3653    77    81]\n",
      " [   55  4145   207    78]\n",
      " [   88  4343    90    86]\n",
      " [   88  4282    73    79]\n",
      " [   88  4269    59    72]\n",
      " [   88  4247    53    70]\n",
      " [   56  4984    81    86]\n",
      " [   58  4888    76    81]\n",
      " [   32  5001   652    77]\n",
      " [   27  5002   346    73]\n",
      " [   24  4997   211    66]\n",
      " [   88  5034   148    89]\n",
      " [   44  5528   165    75]\n",
      " [   88  5728   128   104]\n",
      " [   88  5683    97    94]\n",
      " [   88  5649    73    84]\n",
      " [   56  6299    79    75]\n",
      " [   55  6261    73    72]\n",
      " [   53  6208    71    69]\n",
      " [   51  6172    73    68]\n",
      " [   23  6401   575    73]\n",
      " [   33  6386   419    79]\n",
      " [   30  6396   233    73]\n",
      " [   57  6380   161    84]\n",
      " [   27  6379   159    70]\n",
      " [   88  6445   116    88]\n",
      " [   45  6896   156    77]\n",
      " [   88  7056    74    93]\n",
      " [   88  7025    61    86]\n",
      " [   88  7019    51    78]\n",
      " [   88  6984    45    73]\n",
      " [   58  7673    66    88]\n",
      " [   57  7599    65    83]\n",
      " [   54  7572    65    79]\n",
      " [   53  7524    67    79]\n",
      " [   51  7499    64    74]\n",
      " [   22  7694    54    61]\n",
      " [   34  7690    62    70]\n",
      " [   26  7752    60    62]\n",
      " [   30  7684    73    71]\n",
      " [   27  7691    72    67]\n",
      " [   23  8171 17747    81]\n",
      " [   20  8163 17747    82]\n",
      " [   47  8186 17747    92]\n",
      " [   32  8146   364    78]\n",
      " [   59  8131   179    83]\n",
      " [   56  8141   151    81]\n",
      " [   52  8126    55    72]\n",
      " [   53  8151    70    71]\n",
      " [   88  8381   261   109]\n",
      " [   88  8282   157    97]\n",
      " [   90  9187    73    92]\n",
      " [   88  9159    50    85]\n",
      " [   90  9183    56    79]\n",
      " [   90  9147    46    68]\n",
      " [   90  9116    42    62]\n",
      " [   23  9520    41    49]\n",
      " [   47  9518    43    63]\n",
      " [   20  9637    56    57]\n",
      " [   44  9641    56    70]\n",
      " [   22 10133    68    48]\n",
      " [   46 10127    66    61]\n",
      " [   27 10649    75    49]\n",
      " [   39 10646    69    55]\n",
      " [   22 11159    83    47]\n",
      " [   15 11677    92    42]\n",
      " [   34 12181    71    56]\n",
      " [   42 12399    60    64]\n",
      " [   39 12295    58    61]\n",
      " [   46 12505    64    68]\n",
      " [   51 12619    61    71]\n",
      " [   58 12817    45    68]\n",
      " [   54 12715    45    64]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.083,  0.233, -0.547,  ...,  2.309,  0.725, -0.282],\n",
       "        [-0.083,  0.233, -0.547,  ...,  2.309,  0.725, -0.282],\n",
       "        [-0.083,  0.233, -0.547,  ...,  2.309,  0.725, -0.282],\n",
       "        ...,\n",
       "        [-0.083,  0.233, -0.547,  ...,  2.309,  0.725, -0.282],\n",
       "        [-0.083,  0.233, -0.547,  ...,  2.309,  0.725, -0.282],\n",
       "        [-0.602, -1.223,  1.707,  ...,  6.932, -5.496,  1.588]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.TestAE(events, annotation, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61cb6059",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data...\n",
      "Loading validation data...\n",
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1: 100%|█████████████████████████████████████████████████████| 22921/22921 [06:04<00:00, 62.83it/s]\n",
      "Validation epoch 1: 100%|█████████████████████████████████████████████████████| 2797/2797 [00:51<00:00, 54.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Total training loss: 0.06927790\n",
      "Epoch 1 Total validation loss: 0.06232877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 2:  96%|██████████████████████████████████████████████████▉  | 22050/22921 [05:28<00:12, 72.28it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x17fc7d630>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/evanb/miniconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/evanb/miniconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1442, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Users/evanb/miniconda3/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Users/evanb/miniconda3/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/Users/evanb/miniconda3/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Users/evanb/miniconda3/lib/python3.10/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "Training epoch 2:  96%|██████████████████████████████████████████████████▉  | 22051/22921 [05:29<00:13, 66.87it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mContinueTrainAE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Python/TimeStepMusic/python/run.py:104\u001b[0m, in \u001b[0;36mContinueTrainAE\u001b[0;34m(events, annotation, metadata)\u001b[0m\n\u001b[1;32m     97\u001b[0m ae_train_dataset \u001b[38;5;241m=\u001b[39m train_autoencoder\u001b[38;5;241m.\u001b[39mAutoEncoderDataset(events, annotation, metadata, \n\u001b[1;32m     98\u001b[0m                                                         CHUNK_LENGTH, DATA_TYPE, \n\u001b[1;32m     99\u001b[0m                                                         AUG_TYPE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    100\u001b[0m ae_valid_dataset \u001b[38;5;241m=\u001b[39m train_autoencoder\u001b[38;5;241m.\u001b[39mAutoEncoderDataset(events, annotation, metadata, \n\u001b[1;32m    101\u001b[0m                                                         CHUNK_LENGTH, DATA_TYPE, \n\u001b[1;32m    102\u001b[0m                                                         AUG_TYPE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 104\u001b[0m \u001b[43mtrain_autoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mae_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mae_train_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mae_valid_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATA_TYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m                        \u001b[49m\u001b[43maug_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAUG_TYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_chunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_CHUNK_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mchunk_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCHUNK_LENGTH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpedal_bins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPEDAL_BINS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAE_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAE_LEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAE_BATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAE_MODEL_FILE_NAME\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Python/TimeStepMusic/python/train_autoencoder.py:137\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataset, valid_dataset, data_type, aug_type, max_chunk_size, chunk_length, pedal_bins, epochs, lr, batch_size, model_path, model_file)\u001b[0m\n\u001b[1;32m    135\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    136\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 137\u001b[0m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    139\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/optim/adam.py:334\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# update step\u001b[39;00m\n\u001b[1;32m    332\u001b[0m step_t \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight_decay \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    335\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39madd(param, alpha\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(param):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run.ContinueTrainAE(events, annotation, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ded49714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizing and encoding data: 100%|██████████████████████████████████████████| 1099/1099 [00:13<00:00, 80.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvDiscriminator(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv1d(20, 40, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
      "    (1): InstanceNorm1d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "    (3): Conv1d(40, 80, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
      "    (4): InstanceNorm1d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (5): LeakyReLU(negative_slope=0.2)\n",
      "    (6): Conv1d(80, 160, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
      "    (7): InstanceNorm1d(160, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (8): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (penultimate_layer): Sequential(\n",
      "    (0): Conv1d(160, 320, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (last_layer): Linear(in_features=320, out_features=1, bias=True)\n",
      ")\n",
      "ConvGenerator(\n",
      "  (first_layer): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=320, bias=True)\n",
      "    (1): InstanceNorm1d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (middle_layers): Sequential(\n",
      "    (0): ConvTranspose1d(160, 80, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
      "    (1): InstanceNorm1d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "    (3): ConvTranspose1d(80, 40, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
      "    (4): InstanceNorm1d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (5): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (last_layer): Sequential(\n",
      "    (0): ConvTranspose1d(40, 20, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n",
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   0%|                                                    | 511/255540 [00:15<1:17:55, 54.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 500\n",
      "Tot disc loss: 4.05728 partial_disc_error: -0.023951265960931778 grad_error: 4.08123\n",
      "Tot gen loss: -0.03331 partial_gen_error: -0.038218237459659576 gen_error_fm: 0.004911374766379595\n",
      "A real sample: [[   38   178   166    57]\n",
      " [   39   445   183    60]\n",
      " [   41   792   207    58]\n",
      " [   39  1382   166    54]\n",
      " [   38  1672   174    53]\n",
      " [   39  2026   211    52]\n",
      " [   90  2849 17747    72]\n",
      " [   36  2643   208    40]\n",
      " [   41  3354   401    59]\n",
      " [   37  3360   238    54]]\n",
      "Disc probability of real sample: 0.09730401635169983\n",
      "A fake sample: [[  88 2474   28   34]]\n",
      "Disc probability of fake sample: 0.01332886517047882\n",
      "An interpolated sample: [[  50  140   86   53]\n",
      " [  51  355  117   59]\n",
      " [  52 1341   77   44]\n",
      " [  51 1581   90   51]\n",
      " [  51 1996   72   38]\n",
      " [  89 2784  130   60]\n",
      " [  53 3278  130   49]]\n",
      "Disc probability of interpolated sample: 0.07371358573436737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   0%|▏                                                  | 1009/255540 [00:24<1:15:06, 56.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 1000\n",
      "Tot disc loss: 19.53729 partial_disc_error: -0.0201676394790411 grad_error: 19.55746\n",
      "Tot gen loss: -0.04171 partial_gen_error: -0.04643025994300842 gen_error_fm: 0.004723130725324154\n",
      "A real sample: [[   32   212   301    48]\n",
      " [   51   210   185    57]\n",
      " [   88   202   194    74]\n",
      " [   36    75   122    49]\n",
      " [   39   393   142    57]\n",
      " [   88   419   114    78]\n",
      " [   88   372   105    76]\n",
      " [   88   335    80    72]\n",
      " [   88   298    67    69]\n",
      " [   88   287    37    55]\n",
      " [   42   573    96    55]\n",
      " [   42   935   147    57]\n",
      " [   48   919   124    60]\n",
      " [   39   738   108    52]\n",
      " [   39  1105   126    53]\n",
      " [   32  1280    70    25]\n",
      " [   88  1432    73    56]\n",
      " [   88  1393    60    56]\n",
      " [   88  1393    57    57]\n",
      " [   49  1304    54    44]\n",
      " [   88  1347    45    56]\n",
      " [   88  1314    36    61]\n",
      " [   41  1662   144    64]\n",
      " [   37  1471   119    59]\n",
      " [   88  1465   109    78]\n",
      " [   37  1814   105    46]\n",
      " [   58  2004   152    59]\n",
      " [   41  2053   131    51]\n",
      " [   32  2351   215    43]\n",
      " [   56  2366   150    57]\n",
      " [   88  2384   172    72]\n",
      " [   37  2218   117    48]\n",
      " [   34  2516   128    40]\n",
      " [   55  2523   107    54]\n",
      " [   88  2450   111    68]\n",
      " [   55  2730   205    53]\n",
      " [   37  2746   162    45]\n",
      " [   34  2883   199    43]\n",
      " [   37  3065   159    49]\n",
      " [   34  3232   124    49]\n",
      " [   32  3465 17747    39]\n",
      " [   56  3443   391    53]\n",
      " [   36  3466   242    43]\n",
      " [   48  3820   200    55]]\n",
      "Disc probability of real sample: 0.04740249738097191\n",
      "A fake sample: [[  88 1473   36   52]\n",
      " [  86 2896   15   26]\n",
      " [  76 3360    0   41]]\n",
      "Disc probability of fake sample: 0.020441627129912376\n",
      "An interpolated sample: [[  32  201  218   47]\n",
      " [  51  199  152   55]\n",
      " [  88  192  158   71]\n",
      " [  37   76  108   48]\n",
      " [  39  380  130   56]\n",
      " [  88  408  107   75]\n",
      " [  88  368   97   73]\n",
      " [  88  331   75   70]\n",
      " [  88  295   64   67]\n",
      " [  88  288   36   55]\n",
      " [  42  568   84   54]\n",
      " [  42  923  134   55]\n",
      " [  48  904  115   57]\n",
      " [  39  742  100   50]\n",
      " [  39 1098  107   53]\n",
      " [  32 1273   64   24]\n",
      " [  88 1418   67   54]\n",
      " [  88 1383   56   54]\n",
      " [  88 1385   52   55]\n",
      " [  49 1302   51   44]\n",
      " [  88 1341   43   55]\n",
      " [  41 1649  126   63]\n",
      " [  37 1472  108   58]\n",
      " [  88 1473   98   75]\n",
      " [  37 1807   90   43]\n",
      " [  58 1996  127   56]\n",
      " [  41 2052  113   49]\n",
      " [  32 2343  177   44]\n",
      " [  56 2360  132   55]\n",
      " [  88 2371  146   70]\n",
      " [  37 2218  105   49]\n",
      " [  34 2512  110   39]\n",
      " [  55 2518   95   52]\n",
      " [  88 2446   97   65]\n",
      " [  55 2735  189   53]\n",
      " [  37 2741  151   45]\n",
      " [  33 2883  163   41]\n",
      " [  37 3059  135   48]\n",
      " [  34 3225  117   51]\n",
      " [  32 3455  415   39]\n",
      " [  56 3445  261   52]\n",
      " [  36 3460  186   42]\n",
      " [  48 3805  162   54]]\n",
      "Disc probability of interpolated sample: 0.03703773394227028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   1%|▎                                                  | 1507/255540 [00:33<1:20:16, 52.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 1500\n",
      "Tot disc loss: 5.64533 partial_disc_error: -0.02714572474360466 grad_error: 5.67248\n",
      "Tot gen loss: -0.01117 partial_gen_error: -0.01605813577771187 gen_error_fm: 0.004889276809990406\n",
      "A real sample: [[  88  875  166   66]\n",
      " [  88 1147   66   46]\n",
      " [  88 1124   54   44]\n",
      " [  15 1258   97   42]\n",
      " [  27 1246   89   50]\n",
      " [  88 1321   95   77]\n",
      " [  88 1265   58   68]\n",
      " [  88 1724  193   83]\n",
      " [  88 2006  218   65]\n",
      " [  88 3832   66   53]]\n",
      "Disc probability of real sample: 0.03361830860376358\n",
      "A fake sample: [[  88 2483    6   41]\n",
      " [  75 3381   24   50]]\n",
      "Disc probability of fake sample: -0.008257748559117317\n",
      "An interpolated sample: [[  76 1041   15   24]\n",
      " [  51 1243   69   40]\n",
      " [  52 1217   65   43]\n",
      " [  75 1730   59   52]\n",
      " [  88 1975   63   61]\n",
      " [  88 3741   43   49]]\n",
      "Disc probability of interpolated sample: 0.07306933403015137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   1%|▍                                                  | 2005/255540 [00:42<1:24:44, 49.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 2000\n",
      "Tot disc loss: 9.26500 partial_disc_error: 0.009028397500514984 grad_error: 9.25597\n",
      "Tot gen loss: -0.00575 partial_gen_error: -0.010611618869006634 gen_error_fm: 0.004864681977778673\n",
      "A real sample: [[  52  181   53   49]\n",
      " [  54  105   53   51]\n",
      " [  52   30   52   49]\n",
      " [  54  457   46   41]\n",
      " [  52  354   46   41]\n",
      " [  39  272   50   37]\n",
      " [  51  256   53   49]\n",
      " [  35  595   43   47]\n",
      " [  52  680   45   57]\n",
      " [  51  604   49   57]\n",
      " [  52  520   51   59]\n",
      " [  52  852   79   53]\n",
      " [  54  775   72   53]\n",
      " [  54 1155   60   52]\n",
      " [  45  966   61   48]\n",
      " [  52 1031   61   53]\n",
      " [  51  994   62   55]\n",
      " [  42 1307   45   44]\n",
      " [  52 1384   47   51]\n",
      " [  51 1314   49   51]\n",
      " [  52 1238   50   54]\n",
      " [  39 1630   58   47]\n",
      " [  51 1660   58   54]\n",
      " [  52 1567   56   54]\n",
      " [  54 1484   53   55]\n",
      " [  52 1905   57   48]\n",
      " [  54 1841   56   49]\n",
      " [  52 1742   54   48]\n",
      " [  33 1964   59   47]\n",
      " [  52 2073   58   60]\n",
      " [  51 1992   57   57]\n",
      " [   9 2333  452   87]\n",
      " [  21 2297  350   92]\n",
      " [  51 2363  279  100]\n",
      " [  52 2302  193   95]\n",
      " [  54 2208  136   88]\n",
      " [  88 2335  107   94]\n",
      " [  88 2284   50   72]\n",
      " [  88 2260   55   75]\n",
      " [  88 2227   26   53]\n",
      " [  53 2584   71   80]\n",
      " [  54 2503   68   77]\n",
      " [  53 2419   63   71]\n",
      " [  54 2819   74   75]\n",
      " [  53 2758   70   72]\n",
      " [  51 2669   64   66]\n",
      " [  53 3072   69   73]\n",
      " [  51 2988   66   70]\n",
      " [  53 2895   61   66]\n",
      " [  51 3310   56   71]\n",
      " [  53 3230   56   69]\n",
      " [  54 3157   53   66]\n",
      " [  51 3541   53   56]\n",
      " [  53 3470   54   57]\n",
      " [  54 3384   53   57]\n",
      " [  88 3433   49   68]\n",
      " [  10 3606   77   34]\n",
      " [  46 3739   82   57]\n",
      " [  22 3606   91   51]\n",
      " [  50 3761   86   65]\n",
      " [  50 3676   74   62]]\n",
      "Disc probability of real sample: 0.03734249249100685\n",
      "A fake sample: [[  75 1448   13   43]\n",
      " [  88 2954   12   30]\n",
      " [  62 3474   19   47]]\n",
      "Disc probability of fake sample: 0.006300533190369606\n",
      "An interpolated sample: [[  63  127   34   47]\n",
      " [  76  372   46   40]\n",
      " [  75  327   43   41]\n",
      " [  69  515   19   41]\n",
      " [  63  589   22   44]\n",
      " [  76  787   39   53]\n",
      " [  65 1042   16   41]\n",
      " [  77 1012   20   43]\n",
      " [  77 1239   57   53]\n",
      " [  63 1306   52   50]\n",
      " [  64 1504   14   38]\n",
      " [  64 1564   18   42]\n",
      " [  75 1766   31   30]\n",
      " [  55 1920    0   45]\n",
      " [  54 2260  105   67]\n",
      " [  66 2209   95   71]\n",
      " [  64 2255   80   67]\n",
      " [  64 2246   73   70]\n",
      " [  63 2499   25   48]\n",
      " [  64 2758   45   53]\n",
      " [  77 3015   29   47]\n",
      " [  76 2959   29   48]\n",
      " [  77 3211   24   50]\n",
      " [  62 3519   24   51]\n",
      " [  77 3417   26   55]\n",
      " [  42 3648   34   34]\n",
      " [  67 3645   37   49]]\n",
      "Disc probability of interpolated sample: -0.02070539817214012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   1%|▌                                                  | 2510/255540 [00:51<1:16:36, 55.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 2500\n",
      "Tot disc loss: 4.11842 partial_disc_error: -0.021878201514482498 grad_error: 4.14030\n",
      "Tot gen loss: -0.03607 partial_gen_error: -0.04064066708087921 gen_error_fm: 0.004568161442875862\n",
      "A real sample: [[  54  187   69   51]\n",
      " [  59  418  465   49]\n",
      " [  31  391  432   41]\n",
      " [  43  402  228   47]\n",
      " [  55  378  148   54]\n",
      " [  88  459  136   68]\n",
      " [  88  407   86   60]\n",
      " [  50  649  124   71]\n",
      " [  88  566  105   85]\n",
      " [  88  512   80   76]\n",
      " [  56  880  240   51]\n",
      " [  38  843  193   44]\n",
      " [  50  864  144   48]\n",
      " [  47 1082   69   51]\n",
      " [  35 1360  402   35]\n",
      " [  47 1359  261   45]\n",
      " [  55 1327  212   51]\n",
      " [  43 1608   83   52]\n",
      " [  39 1914  111   63]\n",
      " [  88 1920   95   82]\n",
      " [  55 1941  349   62]\n",
      " [  51 1979  227   60]\n",
      " [  88 2052  204   77]\n",
      " [  88 2010  112   70]\n",
      " [  88 1975   88   68]\n",
      " [  50 2235  105   55]\n",
      " [  54 2629  458   56]\n",
      " [  24 2565  309   43]\n",
      " [  38 2573  196   47]\n",
      " [  88 2580  126   64]\n",
      " [  88 2815  205  103]\n",
      " [  88 2739  138   93]\n",
      " [  88 2676   95   81]\n",
      " [  48 2956   89   33]\n",
      " [  51 3244  306   47]\n",
      " [  48 3255  216   46]\n",
      " [  36 3202  151   39]\n",
      " [  46 3491   90   44]\n",
      " [  46 3757  313   49]\n",
      " [  34 3699  240   47]\n",
      " [  50 3770  187   53]\n",
      " [  88 3761  139   68]]\n",
      "Disc probability of real sample: 0.03604694455862045\n",
      "A fake sample: [[  76 1451   14   41]\n",
      " [  88 2912    0   36]]\n",
      "Disc probability of fake sample: -0.0028612688183784485\n",
      "An interpolated sample: [[  88 1272   28   26]\n",
      " [  76 1452   14   41]\n",
      " [  88 2912    0   36]\n",
      " [  87 3661   22   40]]\n",
      "Disc probability of interpolated sample: -0.03279899060726166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   1%|▌                                                  | 3008/255540 [01:00<1:13:47, 57.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 3000\n",
      "Tot disc loss: 2.69338 partial_disc_error: -0.01614880934357643 grad_error: 2.70953\n",
      "Tot gen loss: -0.05269 partial_gen_error: -0.05724368616938591 gen_error_fm: 0.004555173218250275\n",
      "A real sample: [[   35    99   375    82]\n",
      " [   43   138   280    86]\n",
      " [   40   144   204    80]\n",
      " [   38   134   161    75]\n",
      " [   50   124   127    78]\n",
      " [   88   173   105    87]\n",
      " [   47   402   117    80]\n",
      " [   88   370    96    93]\n",
      " [   88   353    91    89]\n",
      " [   88   332    74    84]\n",
      " [   88   306    65    79]\n",
      " [   88   298    40    65]\n",
      " [   43   667   196    74]\n",
      " [   50   947   178    80]\n",
      " [    9  1268    61    58]\n",
      " [   21  1258    65    66]\n",
      " [   88  1435    70    92]\n",
      " [   88  1385    51    83]\n",
      " [   88  1329    47    78]\n",
      " [   88  1462   151   107]\n",
      " [   88  1440   107    98]\n",
      " [   33  1710 17747    78]\n",
      " [   45  1729   533    83]\n",
      " [   42  1680   413    81]\n",
      " [   38  1690   256    78]\n",
      " [   50  1687   164    80]\n",
      " [   54  2023   195    81]\n",
      " [   33  2306 17747    67]\n",
      " [   45  2333  4555    76]\n",
      " [   57  2324   358    79]\n",
      " [   42  2297   191    67]\n",
      " [   38  2310   177    67]\n",
      " [   50  2282   178    79]\n",
      " [   47  2743 17747    62]\n",
      " [   35  2672 17747    60]\n",
      " [   43  2708   635    63]\n",
      " [   54  2736   253    68]\n",
      " [   38  2721   206    62]\n",
      " [   88  2833   163    83]\n",
      " [   88  2778    50    73]\n",
      " [   88  3001   194   105]\n",
      " [   88  2938   129    95]\n",
      " [   50  3140   232    71]\n",
      " [   47  3607   208    64]]\n",
      "Disc probability of real sample: 0.11665411293506622\n",
      "A fake sample: [[  78  960    0   25]\n",
      " [  88 3419    8   51]]\n",
      "Disc probability of fake sample: 0.0603000670671463\n",
      "An interpolated sample: [[  46   89  177   77]\n",
      " [  55  119  154   79]\n",
      " [  52  134  127   74]\n",
      " [  50  121  112   71]\n",
      " [  62  105   94   73]\n",
      " [  57  373   94   73]\n",
      " [  88  345   82   83]\n",
      " [  88  335   75   79]\n",
      " [  88  314   63   76]\n",
      " [  88  291   55   72]\n",
      " [  54  645  127   69]\n",
      " [  62  919  144   76]\n",
      " [  20 1243   54   52]\n",
      " [  32 1253   57   59]\n",
      " [  88 1415   60   81]\n",
      " [  88 1366   45   75]\n",
      " [  88 1466  107   94]\n",
      " [  88 1443   83   86]\n",
      " [  44 1706  269   68]\n",
      " [  44 1723  201   71]\n",
      " [  54 1681  178   71]\n",
      " [  50 1693  147   71]\n",
      " [  53 2011  117   73]\n",
      " [  44 2299  332   61]\n",
      " [  56 2312  244   68]\n",
      " [  68 2309  178   71]\n",
      " [  53 2294  129   62]\n",
      " [  50 2294  121   62]\n",
      " [  58 2734  362   58]\n",
      " [  45 2662  296   55]\n",
      " [  55 2707  201   58]\n",
      " [  54 2729  145   63]\n",
      " [  50 2720  130   59]\n",
      " [  88 2806  111   76]\n",
      " [  88 2977  102   91]\n",
      " [  88 2932   80   84]\n",
      " [  62 3152  164   70]\n",
      " [  46 3622  140   60]]\n",
      "Disc probability of interpolated sample: 0.08729001134634018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   1%|▋                                                  | 3506/255540 [01:09<1:24:00, 50.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 3500\n",
      "Tot disc loss: 4.32141 partial_disc_error: 0.027945278212428093 grad_error: 4.29346\n",
      "Tot gen loss: -0.02990 partial_gen_error: -0.0344378836452961 gen_error_fm: 0.004538958892226219\n",
      "A real sample: [[  41  137  133   65]\n",
      " [  39  422  164   75]\n",
      " [  38  301  134   70]\n",
      " [  41  612  141   65]\n",
      " [  39  983  123   58]\n",
      " [  38 1325  132   55]\n",
      " [  43 1664  126   55]\n",
      " [  36 2000  184   51]\n",
      " [  43 2352  112   57]\n",
      " [  42 2477  137   59]\n",
      " [  34 2652  136   52]\n",
      " [  43 2650  122   59]\n",
      " [  33 2982  162   57]\n",
      " [  45 2988  138   64]\n",
      " [  46 3318  141   66]\n",
      " [  31 3326  125   58]\n",
      " [  45 3783  145   71]\n",
      " [  46 3643  130   69]\n",
      " [  39 3638  115   62]]\n",
      "Disc probability of real sample: 0.02630533277988434\n",
      "A fake sample: [[  88  551   29   51]\n",
      " [  75 2900    0   25]\n",
      " [  76 3402   20   42]]\n",
      "Disc probability of fake sample: -0.024579167366027832\n",
      "An interpolated sample: [[  88  566   42   56]\n",
      " [  64 2914    1   27]\n",
      " [  75 3685   33   44]]\n",
      "Disc probability of interpolated sample: 0.0003062225878238678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   2%|▊                                                  | 4005/255540 [01:19<1:33:30, 44.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 4000\n",
      "Tot disc loss: 6.63167 partial_disc_error: -0.0009437426924705505 grad_error: 6.63262\n",
      "Tot gen loss: -0.06348 partial_gen_error: -0.06835438311100006 gen_error_fm: 0.004877633880823851\n",
      "A real sample: [[  31  168  101   23]\n",
      " [  34   17  108   31]\n",
      " [  26  129   95   31]\n",
      " [  36  171   98   43]\n",
      " [  48  160   85   50]\n",
      " [  88  179   74   65]\n",
      " [  88  135   45   61]\n",
      " [  31  457   82   55]\n",
      " [  26  432   75   53]\n",
      " [  88  399   85   80]\n",
      " [  88  322   54   71]\n",
      " [  31  693   94   45]\n",
      " [  26  680   85   44]\n",
      " [  50  836   74   61]\n",
      " [  31 1036  143   39]\n",
      " [  39 1030  139   47]\n",
      " [  24 1016  135   45]\n",
      " [  51 1027  127   62]\n",
      " [  88 1116  116   78]\n",
      " [  88 1074   60   63]\n",
      " [  88 1040   38   57]\n",
      " [  88 1038   47   62]\n",
      " [  88 1017   30   60]\n",
      " [  31 1338   70   43]\n",
      " [  24 1351   74   44]\n",
      " [  31 1357   75   49]\n",
      " [  88 1448  237  111]\n",
      " [  24 1596  147   71]\n",
      " [  31 1901  122   53]\n",
      " [  45 1884  117   63]\n",
      " [  25 1920  101   51]\n",
      " [  88 1920   89   75]\n",
      " [  88 1860   69   70]\n",
      " [  33 1922  160   57]\n",
      " [  88 2118  131   84]\n",
      " [  88 2068  113   80]\n",
      " [  88 2021   86   76]\n",
      " [  88 1986   72   72]\n",
      " [  31 2204   66   45]\n",
      " [  25 2199   65   46]\n",
      " [  31 2509   52   52]\n",
      " [  25 2486   52   50]\n",
      " [  33 2868  410   55]\n",
      " [  30 2872  318   57]\n",
      " [  45 2867  235   65]\n",
      " [  26 2833  156   52]\n",
      " [  88 2873  120   75]\n",
      " [  88 3089   48   75]\n",
      " [  88 3048   41   68]\n",
      " [  30 3221   52   58]\n",
      " [  26 3227   51   57]\n",
      " [  90 3248   79   84]\n",
      " [  88 3173   36   71]\n",
      " [  30 3524   58   49]\n",
      " [  26 3489   57   49]\n",
      " [  30 3803   95   54]\n",
      " [  27 3792   85   53]\n",
      " [  88 3785   88   78]]\n",
      "Disc probability of real sample: 0.05405039340257645\n",
      "A fake sample: [[  88 1004    3   59]\n",
      " [  87 1479   17   26]\n",
      " [  88 3395    0   40]]\n",
      "Disc probability of fake sample: 0.0696154311299324\n",
      "An interpolated sample: [[  42  150   74   26]\n",
      " [  45   20   79   32]\n",
      " [  38  122   73   33]\n",
      " [  49  154   74   43]\n",
      " [  49  139   67   49]\n",
      " [  88  153   60   61]\n",
      " [  43  433   66   55]\n",
      " [  38  421   62   53]\n",
      " [  88  377   67   75]\n",
      " [  42  664   78   48]\n",
      " [  38  662   72   46]\n",
      " [  50  817   64   57]\n",
      " [  42 1033   91   42]\n",
      " [  52 1029   90   48]\n",
      " [  37 1020   92   46]\n",
      " [  51 1020   89   60]\n",
      " [  88 1088   83   73]\n",
      " [  88 1060   47   60]\n",
      " [  88 1026   34   53]\n",
      " [  88 1028   39   59]\n",
      " [  42 1329   68   42]\n",
      " [  37 1320   69   43]\n",
      " [  88 1454  147   95]\n",
      " [  36 1571  103   62]\n",
      " [  43 1867   89   49]\n",
      " [  56 1858   87   57]\n",
      " [  38 1912   79   47]\n",
      " [  88 1902   71   68]\n",
      " [  32 1920   99   51]\n",
      " [  88 2094   87   76]\n",
      " [  88 2057   78   73]\n",
      " [  88 2008   65   70]\n",
      " [  42 2200   61   44]\n",
      " [  37 2195   58   45]\n",
      " [  43 2499   41   45]\n",
      " [  38 2482   42   45]\n",
      " [  44 2833  189   51]\n",
      " [  41 2817  171   51]\n",
      " [  56 2861  144   58]\n",
      " [  38 2830  112   50]\n",
      " [  88 3052   34   65]\n",
      " [  88 3027   30   62]\n",
      " [  42 3202   46   54]\n",
      " [  38 3235   46   52]\n",
      " [  90 3227   66   76]\n",
      " [  41 3507   40   47]\n",
      " [  38 3481   41   48]\n",
      " [  41 3776   75   52]\n",
      " [  39 3765   70   52]]\n",
      "Disc probability of interpolated sample: 0.041051074862480164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   2%|▉                                                  | 4509/255540 [01:29<1:15:53, 55.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 4500\n",
      "Tot disc loss: 4.11027 partial_disc_error: -0.010091710835695267 grad_error: 4.12036\n",
      "Tot gen loss: -0.00682 partial_gen_error: -0.011548181995749474 gen_error_fm: 0.00472868699580431\n",
      "A real sample: [[  31  193   93   38]\n",
      " [  40  189   83   45]\n",
      " [  43  372  133   50]\n",
      " [  88  670  175   70]\n",
      " [  48  564  122   48]\n",
      " [  88  504  103   61]\n",
      " [  31  850  656   28]\n",
      " [  52  878  317   41]\n",
      " [  24  849  234   31]\n",
      " [  36  847  196   43]\n",
      " [  88  876  126   63]\n",
      " [  64 1083  112   60]\n",
      " [  88 1143   97   69]\n",
      " [  55 1420   47   63]\n",
      " [  60 1267   43   61]\n",
      " [  52 1577   73   56]\n",
      " [  43 1902   74   53]\n",
      " [  28 1890   74   48]\n",
      " [  48 1747   72   56]\n",
      " [  40 2058  158   48]\n",
      " [  88 1988  130   69]\n",
      " [  36 2235  137   50]\n",
      " [  43 2556  103   56]\n",
      " [  31 2417  101   50]\n",
      " [  40 2414   93   54]\n",
      " [  48 2738   84   53]\n",
      " [  52 2983  124   57]\n",
      " [  24 2990  113   45]\n",
      " [  88 3025  129   76]\n",
      " [  88 2963   76   68]\n",
      " [  88 2917   66   67]\n",
      " [  88 2911   36   53]\n",
      " [  43 3324   69   52]\n",
      " [  48 3135   62   53]\n",
      " [  31 3523  276   39]\n",
      " [  40 3528  206   45]\n",
      " [  55 3486  167   55]\n",
      " [  48 3683  111   56]]\n",
      "Disc probability of real sample: 0.07985381036996841\n",
      "A fake sample: [[  88  519   15   48]\n",
      " [  74 3395   18   64]]\n",
      "Disc probability of fake sample: -0.013683026656508446\n",
      "An interpolated sample: [[  31  185   86   39]\n",
      " [  40  183   78   45]\n",
      " [  43  362  126   50]\n",
      " [  88  661  152   69]\n",
      " [  48  562  110   48]\n",
      " [  88  505   94   60]\n",
      " [  31  844  369   27]\n",
      " [  52  869  245   40]\n",
      " [  24  846  193   30]\n",
      " [  36  844  169   42]\n",
      " [  88  868  112   61]\n",
      " [  64 1079  101   60]\n",
      " [  88 1136   89   68]\n",
      " [  55 1411   45   61]\n",
      " [  60 1271   41   59]\n",
      " [  52 1569   66   53]\n",
      " [  43 1893   72   52]\n",
      " [  28 1881   71   47]\n",
      " [  48 1744   69   55]\n",
      " [  40 2052  133   46]\n",
      " [  88 1987  113   67]\n",
      " [  36 2239  129   52]\n",
      " [  43 2550   94   54]\n",
      " [  31 2415   93   49]\n",
      " [  40 2410   86   52]\n",
      " [  48 2736   82   52]\n",
      " [  52 2974  105   55]\n",
      " [  24 2989   97   44]\n",
      " [  88 3022  111   74]\n",
      " [  88 2958   68   67]\n",
      " [  88 2914   60   66]\n",
      " [  88 2912   33   53]\n",
      " [  43 3309   63   51]\n",
      " [  48 3133   57   51]\n",
      " [  31 3516  217   40]\n",
      " [  40 3527  173   47]\n",
      " [  55 3484  143   55]\n",
      " [  48 3681  101   54]]\n",
      "Disc probability of interpolated sample: 0.08194883167743683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   2%|▉                                                  | 5005/255540 [01:40<1:28:59, 46.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 5000\n",
      "Tot disc loss: 6.44076 partial_disc_error: -0.0087224580347538 grad_error: 6.44948\n",
      "Tot gen loss: -0.02010 partial_gen_error: -0.024632293730974197 gen_error_fm: 0.0045280978083610535\n",
      "A real sample: [[  46  390  153   64]\n",
      " [  18  369  167   54]\n",
      " [  30  355  138   60]\n",
      " [  39  376  117   63]\n",
      " [  88  457  104   82]\n",
      " [  88  407   68   70]\n",
      " [  88  365   42   63]\n",
      " [  88  523  311  108]\n",
      " [  34  830  169   58]\n",
      " [  39  857  141   61]\n",
      " [  46 1204  205   65]\n",
      " [  17 1602  163   44]\n",
      " [  29 1603  158   53]\n",
      " [  41 1623  131   58]\n",
      " [  37 1612  107   56]\n",
      " [  88 1652   89   74]\n",
      " [  88 1593   57   61]\n",
      " [  88 1829  206  108]\n",
      " [  88 1746  135   97]\n",
      " [  34 2042   50   51]\n",
      " [  41 2029   52   56]\n",
      " [  37 2027   52   52]\n",
      " [  58 2515  171   67]\n",
      " [  26 2518  153   52]\n",
      " [  88 2631  131   78]\n",
      " [  88 2584   80   68]\n",
      " [  29 2876  123   67]\n",
      " [  27 2705  105   63]\n",
      " [  88 2801  103   87]\n",
      " [  88 2742   64   76]\n",
      " [  27 3035  210   69]\n",
      " [  46 2901  180   78]\n",
      " [  54 2969  142   76]\n",
      " [  88 3073  117   87]\n",
      " [  34 3006  105   68]\n",
      " [  46 3288  187   63]\n",
      " [  88 3127  153   81]\n",
      " [  54 3247  113   64]\n",
      " [  88 3262   93   73]\n",
      " [  88 3414  190  104]\n",
      " [  29 3810  249   64]\n",
      " [  28 3619  206   62]\n",
      " [  88 3812  147   86]\n",
      " [  54 3750  106   67]\n",
      " [  88 3783   98   81]\n",
      " [  88 3755   50   60]\n",
      " [  88 3762   43   64]\n",
      " [  42 3714   62   60]]\n",
      "Disc probability of real sample: 0.020498687401413918\n",
      "A fake sample: [[  88 1516   23   46]\n",
      " [  87 1683   33   33]\n",
      " [  88 2468    5   48]\n",
      " [  76 3366   23   48]]\n",
      "Disc probability of fake sample: 0.09470994025468826\n",
      "An interpolated sample: [[  57  379  123   62]\n",
      " [  30  352  132   53]\n",
      " [  42  356  112   57]\n",
      " [  39  370   97   60]\n",
      " [  88  434   87   76]\n",
      " [  88  392   60   66]\n",
      " [  88  517  185   96]\n",
      " [  45  820  135   57]\n",
      " [  39  844  117   59]\n",
      " [  45 1220  168   65]\n",
      " [  29 1594  121   44]\n",
      " [  41 1590  118   52]\n",
      " [  41 1620  102   56]\n",
      " [  50 1607   85   55]\n",
      " [  88 1630   73   68]\n",
      " [  88 1803  157   96]\n",
      " [  88 1733  109   87]\n",
      " [  33 2030   39   47]\n",
      " [  41 2029   42   54]\n",
      " [  57 2512  111   64]\n",
      " [  38 2515  103   52]\n",
      " [  88 2614   93   73]\n",
      " [  88 2570   63   65]\n",
      " [  41 2849   98   64]\n",
      " [  27 2690   88   59]\n",
      " [  88 2789   84   80]\n",
      " [  28 3009  121   62]\n",
      " [  45 2900  114   71]\n",
      " [  54 2976   96   69]\n",
      " [  88 3055   85   80]\n",
      " [  45 3274  140   60]\n",
      " [  88 3126  122   76]\n",
      " [  65 3249   93   61]\n",
      " [  88 3402  135   95]\n",
      " [  40 3792  157   59]\n",
      " [  40 3606  139   58]\n",
      " [  88 3788  111   79]\n",
      " [  54 3744   84   63]\n",
      " [  88 3765   79   75]\n",
      " [  88 3739   44   57]\n",
      " [  88 3743   37   59]]\n",
      "Disc probability of interpolated sample: 0.014830630272626877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   2%|█                                                  | 5506/255540 [01:49<1:17:18, 53.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 5500\n",
      "Tot disc loss: 4.34760 partial_disc_error: -0.02140684239566326 grad_error: 4.36901\n",
      "Tot gen loss: -0.03111 partial_gen_error: -0.03541448712348938 gen_error_fm: 0.004306735470890999\n",
      "A real sample: [[  32  215   47   67]\n",
      " [  58  124   52   81]\n",
      " [  34   66   53   66]\n",
      " [  53  158   52   75]\n",
      " [  39   99   55   65]\n",
      " [  35  331   37   53]\n",
      " [  41  436   41   58]\n",
      " [  53  407   43   64]\n",
      " [  34  524   34   57]\n",
      " [  46  523   40   66]\n",
      " [  38  606   41   60]\n",
      " [  46  734   27   65]\n",
      " [  27  835   36   59]\n",
      " [  54  800   38   70]\n",
      " [  44  739   41   64]\n",
      " [  30 1132   31   45]\n",
      " [  34  968   40   50]\n",
      " [  51 1118   39   58]\n",
      " [  54 1051   41   60]\n",
      " [  39 1045   50   56]\n",
      " [  59 1432   20   56]\n",
      " [  34 1253   28   45]\n",
      " [  39 1362   32   47]\n",
      " [  51 1338   38   57]\n",
      " [  59 1673   36   55]\n",
      " [  35 1570   44   45]\n",
      " [  39 1638   45   47]\n",
      " [  33 1536   61   50]\n",
      " [  32 1875   44   44]\n",
      " [  29 1742   46   43]\n",
      " [  62 1747   47   59]\n",
      " [  30 2072   53   51]\n",
      " [  39 1969   52   54]\n",
      " [  63 2026   52   66]\n",
      " [  62 1997   47   63]\n",
      " [  27 2376   35   48]\n",
      " [  34 2201   42   53]\n",
      " [  66 2334   42   68]\n",
      " [  39 2292   44   54]\n",
      " [  63 2289   43   64]\n",
      " [  34 2582   34   52]\n",
      " [  30 2499   38   51]\n",
      " [  66 2555   41   68]\n",
      " [  22 2674   45   49]\n",
      " [  27 2785   49   55]\n",
      " [  70 2655   55   75]\n",
      " [  22 2999   33   51]\n",
      " [  26 3095   42   57]\n",
      " [  70 2994   51   79]\n",
      " [  30 2901   48   57]\n",
      " [  70 2880   42   70]\n",
      " [  15 3319   39   56]\n",
      " [  29 3194   45   63]\n",
      " [  70 3262   48   80]\n",
      " [  75 3302   34   75]\n",
      " [  88 3292   37   74]\n",
      " [  22 3546   81   64]\n",
      " [  18 3444   77   61]\n",
      " [  88 3471   92   93]\n",
      " [  88 3394   58   82]\n",
      " [  30 3745   51   65]\n",
      " [  27 3642   52   63]\n",
      " [  88 3750   55   86]]\n",
      "Disc probability of real sample: 0.022890426218509674\n",
      "A fake sample: [[  88  998    0   43]\n",
      " [  75 1440    0   31]\n",
      " [  88 2679   35   41]\n",
      " [  87 3440   26   40]]\n",
      "Disc probability of fake sample: 0.07502768933773041\n",
      "An interpolated sample: [[  65   77   19   52]\n",
      " [  77  257   36   44]\n",
      " [  65  491    6   43]\n",
      " [  76 1013    0   39]\n",
      " [  88 1245   27   38]\n",
      " [  77 1450    0   24]\n",
      " [  64 1935   13   43]\n",
      " [  74 2251   45   51]\n",
      " [  75 2510   28   50]\n",
      " [  88 2670   37   42]\n",
      " [  67 2880    0   30]\n",
      " [  74 3213   35   51]\n",
      " [  76 3473   32   44]\n",
      " [  76 3674   34   52]]\n",
      "Disc probability of interpolated sample: 0.04973848536610603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   2%|█▏                                                 | 6009/255540 [01:58<1:24:21, 49.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 6000\n",
      "Tot disc loss: 7.00381 partial_disc_error: 0.007192987948656082 grad_error: 6.99662\n",
      "Tot gen loss: -0.04026 partial_gen_error: -0.04448239505290985 gen_error_fm: 0.004218351561576128\n",
      "A real sample: [[   88   133    51   103]\n",
      " [   35   152    56    77]\n",
      " [   39   194    53    74]\n",
      " [   31    47    62    67]\n",
      " [   62    99    61    80]\n",
      " [   32   460   174    96]\n",
      " [   88   240   156   119]\n",
      " [   47   331   106    91]\n",
      " [   59   354    97    92]\n",
      " [   88   450    95    97]\n",
      " [   88   428    66    82]\n",
      " [   44   617   122    91]\n",
      " [   56   611   103    93]\n",
      " [   88   576   108   102]\n",
      " [   88   510    73    91]\n",
      " [   41   882   113    91]\n",
      " [   53   888   103    93]\n",
      " [   17   739    97    71]\n",
      " [   29   733   102    77]\n",
      " [   38  1149   142   108]\n",
      " [   50  1112   129   106]\n",
      " [   14  1060   116    87]\n",
      " [   27  1048    99    83]\n",
      " [   88  1171    86   102]\n",
      " [   35  1068    66    75]\n",
      " [   88  1121    59    79]\n",
      " [   18   997    65    62]\n",
      " [   47  1432    92    80]\n",
      " [   88  1261    86    95]\n",
      " [   35  1246    80    66]\n",
      " [   88  1338    69    84]\n",
      " [   10  1575    37    81]\n",
      " [   22  1543    43    87]\n",
      " [   88  1680    54   112]\n",
      " [   88  1651    45   102]\n",
      " [   88  1595    44    95]\n",
      " [   88  1536    27    76]\n",
      " [   88  1538    37    63]\n",
      " [   88  1525    32    70]\n",
      " [   34  1841    45    80]\n",
      " [   32  1849    65    82]\n",
      " [   29  1870    66    81]\n",
      " [   34  1740    63    79]\n",
      " [   26  1851    83    78]\n",
      " [   46  1794    69    79]\n",
      " [   88  1881    75    89]\n",
      " [   88  1825    37    72]\n",
      " [   88  1808    34    60]\n",
      " [   88  1795    30    68]\n",
      " [   34  2147 17747    91]\n",
      " [   30  2160 17747    85]\n",
      " [   42  2134   537    89]\n",
      " [   27  2102   245    77]\n",
      " [   38  2086   183    80]\n",
      " [   41  1991   145    79]\n",
      " [   50  1999    71    74]\n",
      " [   52  2003    78    72]\n",
      " [   88  2022    40    67]\n",
      " [   46  2172   428    70]\n",
      " [   51  2170   259    73]\n",
      " [   90  2981    53    53]\n",
      " [   90  2919    45    48]\n",
      " [   22  3579    89    44]\n",
      " [   34  3578    91    53]\n",
      " [   29  3578    91    51]\n",
      " [   38  3546    86    56]]\n",
      "Disc probability of real sample: 0.045772284269332886\n",
      "A fake sample: [[  77  521   27   27]\n",
      " [  88 1504   13   36]\n",
      " [  75 2448    0   43]]\n",
      "Disc probability of fake sample: 0.002139892429113388\n",
      "An interpolated sample: [[  88  118   43   92]\n",
      " [  46  133   46   71]\n",
      " [  51  172   43   68]\n",
      " [  42   55   52   64]\n",
      " [  43  429  127   88]\n",
      " [  88  240  118  106]\n",
      " [  46  349   87   81]\n",
      " [  58  371   83   84]\n",
      " [  88  422   76   86]\n",
      " [  56  600   93   79]\n",
      " [  67  596   82   81]\n",
      " [  88  572   81   87]\n",
      " [  53  856   86   78]\n",
      " [  53  848   80   78]\n",
      " [  29  737   76   60]\n",
      " [  50 1111   84   95]\n",
      " [  62 1097   80   94]\n",
      " [  27 1057   79   79]\n",
      " [  39 1046   70   75]\n",
      " [  88 1139   63   91]\n",
      " [  46 1050   52   72]\n",
      " [  88 1089   46   70]\n",
      " [  58 1400   78   71]\n",
      " [  88 1242   75   83]\n",
      " [  34 1251   70   58]\n",
      " [  20 1567   27   71]\n",
      " [  32 1540   33   76]\n",
      " [  88 1656   43   97]\n",
      " [  88 1618   36   89]\n",
      " [  88 1563   36   84]\n",
      " [  88 1522   22   69]\n",
      " [  88 1519   32   57]\n",
      " [  45 1824   41   75]\n",
      " [  43 1820   56   76]\n",
      " [  41 1842   57   75]\n",
      " [  45 1750   54   72]\n",
      " [  39 1831   67   72]\n",
      " [  57 1778   60   75]\n",
      " [  88 1849   57   78]\n",
      " [  88 1809   32   67]\n",
      " [  45 2111  259   75]\n",
      " [  42 2118  218   73]\n",
      " [  53 2102  184   78]\n",
      " [  39 2076  133   68]\n",
      " [  51 2063  114   72]\n",
      " [  53 1983   99   72]\n",
      " [  50 1999   64   69]\n",
      " [  57 2168  212   67]\n",
      " [  63 2173  159   68]\n",
      " [  89 2951   33   50]\n",
      " [  89 2929   30   47]\n",
      " [  33 3539   63   42]\n",
      " [  45 3547   65   50]\n",
      " [  41 3555   66   48]]\n",
      "Disc probability of interpolated sample: 0.04432099685072899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   3%|█▎                                                 | 6507/255540 [02:07<1:13:41, 56.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 6500\n",
      "Tot disc loss: 5.18034 partial_disc_error: -0.003716837614774704 grad_error: 5.18406\n",
      "Tot gen loss: -0.03394 partial_gen_error: -0.038186244666576385 gen_error_fm: 0.004242404829710722\n",
      "A real sample: [[  88   26   44   47]\n",
      " [  30  163   63   33]\n",
      " [  54  165   51   45]\n",
      " [  64  185   58   57]\n",
      " [  55   57   50   51]\n",
      " [  88  193   44   61]\n",
      " [  51   45   55   64]\n",
      " [  64  113   45   61]\n",
      " [  64   92   47   72]\n",
      " [  76   79   36   60]\n",
      " [  54  404   71   64]\n",
      " [  57  329   73   66]\n",
      " [  62  436   71   70]\n",
      " [  36  383   79   59]\n",
      " [  64  353   65   71]\n",
      " [  88  379   52   71]\n",
      " [  61  300   56   68]\n",
      " [  88  343   39   64]\n",
      " [  58  670   69   78]\n",
      " [  46  561   81   73]\n",
      " [  31  506   78   65]\n",
      " [  57  528   87   81]\n",
      " [  52  588  100   82]\n",
      " [  60  652   99   88]\n",
      " [  88  643   83  100]\n",
      " [  75  562   54   74]\n",
      " [  88  535   36   63]\n",
      " [  76  531   37   67]\n",
      " [  75  533   33   68]\n",
      " [  32  847   31   59]\n",
      " [  58  851   42   75]\n",
      " [  51  929   35   67]\n",
      " [  48  953   51   71]\n",
      " [  61  935   51   75]\n",
      " [  88  940   45   78]\n",
      " [  51  794   55   71]\n",
      " [  64  865   47   70]\n",
      " [  64  843   49   72]\n",
      " [  64  818   37   64]\n",
      " [  59 1058   53   80]\n",
      " [  56 1054   57   79]\n",
      " [  61 1160   53   77]\n",
      " [  88 1130   56   85]\n",
      " [  34 1090   64   67]\n",
      " [  88 1228   18   69]\n",
      " [  57 1401   33   64]\n",
      " [  54 1403   26   58]\n",
      " [  43 1299   36   58]\n",
      " [  57 1291   39   63]\n",
      " [  50 1351   47   65]\n",
      " [  62 1353   61   76]\n",
      " [  52 1333   43   61]\n",
      " [  60 1455   24   54]\n",
      " [  58 1550   33   59]\n",
      " [  48 1634   35   54]\n",
      " [  40 1511   43   53]\n",
      " [  49 1532   49   60]\n",
      " [  60 1549   53   69]\n",
      " [  58 1869   19   56]\n",
      " [  56 1890   28   58]\n",
      " [  39 1852   32   50]\n",
      " [  55 1780   44   62]\n",
      " [  44 1693   47   59]\n",
      " [  48 1829   67   71]\n",
      " [  52 1725   58   67]\n",
      " [  39 1716   55   62]\n",
      " [  46 2047   24   59]\n",
      " [  54 2123   32   66]\n",
      " [  56 2036   34   66]\n",
      " [  52 2049   35   62]\n",
      " [  37 2017   44   57]\n",
      " [  58 2380   26   57]\n",
      " [  39 2400   34   49]\n",
      " [  55 2317   43   62]\n",
      " [  48 2392   45   60]\n",
      " [  56 2229   36   58]\n",
      " [  40 2214   46   58]\n",
      " [  50 2249   67   71]\n",
      " [  58 2585   22   57]\n",
      " [  56 2626   30   60]\n",
      " [  42 2553   42   58]\n",
      " [  51 2580   45   62]\n",
      " [  55 2456   39   61]\n",
      " [  54 2440   44   63]\n",
      " [  46 2739   30   65]\n",
      " [  54 2837   36   71]\n",
      " [  56 2744   40   71]\n",
      " [  40 2727   42   62]\n",
      " [  49 2746   49   67]\n",
      " [  58 3114   32   69]\n",
      " [  51 3109   36   65]\n",
      " [  55 3000   36   64]\n",
      " [  56 2944   38   63]\n",
      " [  58 3300   30   67]\n",
      " [  55 3212   33   64]\n",
      " [  42 3120   42   60]\n",
      " [  48 3151   50   66]\n",
      " [  57 3577   29   54]\n",
      " [  56 3486   33   53]\n",
      " [  57 3383   37   55]\n",
      " [  58 3757   48   63]\n",
      " [  56 3656   48   61]]\n",
      "Disc probability of real sample: 0.04099659621715546\n",
      "A fake sample: [[  76  491    0   52]\n",
      " [  88 1449   23   22]\n",
      " [  75 3389   17   47]]\n",
      "Disc probability of fake sample: 0.006527319550514221\n",
      "An interpolated sample: [[  88   38   36   45]\n",
      " [  41  135   48   34]\n",
      " [  65  142   42   45]\n",
      " [  64  156   44   52]\n",
      " [  66   65   40   49]\n",
      " [  88  154   36   57]\n",
      " [  51   57   50   58]\n",
      " [  76   95   37   56]\n",
      " [  66  347   50   54]\n",
      " [  56  311   53   54]\n",
      " [  62  407   53   59]\n",
      " [  36  369   58   50]\n",
      " [  63  337   49   61]\n",
      " [  88  358   41   62]\n",
      " [  68  625   38   68]\n",
      " [  57  554   47   66]\n",
      " [  42  529   48   61]\n",
      " [  68  536   53   73]\n",
      " [  64  575   62   74]\n",
      " [  73  625   62   79]\n",
      " [  88  608   56   82]\n",
      " [  75  556   40   67]\n",
      " [  43  818   24   51]\n",
      " [  56  806   33   62]\n",
      " [  51  886   29   57]\n",
      " [  61  905   37   60]\n",
      " [  61  902   38   65]\n",
      " [  88  902   37   69]\n",
      " [  51  804   49   63]\n",
      " [  57 1028   27   67]\n",
      " [  67 1056   32   70]\n",
      " [  62 1129   31   67]\n",
      " [  87 1096   35   73]\n",
      " [  88 1236   15   57]\n",
      " [  67 1369   27   54]\n",
      " [  65 1376   21   51]\n",
      " [  55 1307   28   52]\n",
      " [  56 1302   32   56]\n",
      " [  62 1333   36   58]\n",
      " [  62 1451   19   44]\n",
      " [  68 1533   27   47]\n",
      " [  60 1605   27   44]\n",
      " [  51 1520   36   45]\n",
      " [  50 1522   40   51]\n",
      " [  68 1825   20   49]\n",
      " [  68 1839   27   51]\n",
      " [  52 1827   30   47]\n",
      " [  66 1768   37   55]\n",
      " [  55 1704   40   54]\n",
      " [  60 1804   53   64]\n",
      " [  56 2024   15   49]\n",
      " [  66 2088   23   56]\n",
      " [  67 2031   24   55]\n",
      " [  65 2029   26   56]\n",
      " [  68 2340   29   57]\n",
      " [  51 2335   33   52]\n",
      " [  66 2288   39   59]\n",
      " [  60 2350   39   56]\n",
      " [  67 2243   35   57]\n",
      " [  56 2564   18   50]\n",
      " [  68 2570   24   54]\n",
      " [  54 2524   33   52]\n",
      " [  63 2544   35   57]\n",
      " [  56 2734   24   55]\n",
      " [  65 2791   29   59]\n",
      " [  55 2730   30   58]\n",
      " [  40 2722   34   52]\n",
      " [  58 3047   15   55]\n",
      " [  52 3068   20   53]\n",
      " [  53 2983   22   53]\n",
      " [  69 3259   33   60]\n",
      " [  55 3188   34   57]\n",
      " [  53 3120   39   55]\n",
      " [  68 3524   21   50]\n",
      " [  67 3465   24   50]\n",
      " [  68 3737   39   59]\n",
      " [  67 3645   39   58]]\n",
      "Disc probability of interpolated sample: 0.04641875624656677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   3%|█▍                                                 | 7011/255540 [02:16<1:13:34, 56.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 7000\n",
      "Tot disc loss: 5.28192 partial_disc_error: -0.008628994226455688 grad_error: 5.29055\n",
      "Tot gen loss: -0.03133 partial_gen_error: -0.03585842251777649 gen_error_fm: 0.004528178833425045\n",
      "A real sample: [[   19   367 17747    45]\n",
      " [   47   328 17747    61]\n",
      " [   45   312   643    61]\n",
      " [   40   340   262    57]\n",
      " [   36   348   207    58]\n",
      " [   88   594    78    37]\n",
      " [   88   556    66    37]\n",
      " [   88   531    54    37]\n",
      " [   26   752   201    63]\n",
      " [   88   808   151    91]\n",
      " [   88   756   117    83]\n",
      " [   88   720    85    78]\n",
      " [   33  1063   177    46]\n",
      " [   35  1376   183    53]\n",
      " [   36  1656   178    52]\n",
      " [   38  1960    83    54]\n",
      " [   35  2392 17747    40]\n",
      " [   43  2370   484    45]\n",
      " [   39  2348   287    44]\n",
      " [   88  2575    82    37]\n",
      " [   88  2518    68    37]\n",
      " [   88  2483    56    36]\n",
      " [   88  2779   147   100]\n",
      " [   88  2698   108    90]\n",
      " [   88  2696    77    79]\n",
      " [   26  3083   186    46]\n",
      " [   48  3071   140    56]\n",
      " [   35  3653 17747    19]\n",
      " [   43  3616   524    30]\n",
      " [   38  3652   337    33]\n",
      " [   88  3757   227    59]\n",
      " [   50  3632   140    46]\n",
      " [   88  3704   101    59]\n",
      " [   88  3697    39    62]]\n",
      "Disc probability of real sample: 0.016879405826330185\n",
      "A fake sample: [[  62  565   36   53]\n",
      " [  88  976    0   52]\n",
      " [  88 1470    2   15]]\n",
      "Disc probability of fake sample: 0.013098173774778843\n",
      "An interpolated sample: [[  30  330  591   46]\n",
      " [  58  316  324   59]\n",
      " [  56  323  220   58]\n",
      " [  52  340  159   55]\n",
      " [  88  593   65   42]\n",
      " [  88  540   56   41]\n",
      " [  88  543   46   39]\n",
      " [  39  737  112   52]\n",
      " [  88  780   97   76]\n",
      " [  88  753   78   70]\n",
      " [  45 1043  100   49]\n",
      " [  45 1353  137   50]\n",
      " [  49 1618  103   42]\n",
      " [  38 1948   51   45]\n",
      " [  45 2360  357   43]\n",
      " [  55 2331  233   48]\n",
      " [  88 2536   58   35]\n",
      " [  88 2514   50   36]\n",
      " [  88 2765  109   90]\n",
      " [  88 2698   86   83]\n",
      " [  39 3048  110   43]\n",
      " [  49 3052   92   51]\n",
      " [  45 3661  234   22]\n",
      " [  54 3616  192   31]\n",
      " [  50 3652  164   34]\n",
      " [  88 3730  135   55]\n",
      " [  62 3631   98   46]\n",
      " [  88 3691   76   56]]\n",
      "Disc probability of interpolated sample: -0.0008658058941364288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   3%|█▍                                                 | 7509/255540 [02:24<1:12:46, 56.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 7500\n",
      "Tot disc loss: 6.99228 partial_disc_error: 0.0007275734096765518 grad_error: 6.99155\n",
      "Tot gen loss: -0.03711 partial_gen_error: -0.04160187393426895 gen_error_fm: 0.004493526183068752\n",
      "A real sample: [[  39  458   46   62]\n",
      " [  41  344   48   61]\n",
      " [  42  253   50   59]\n",
      " [  37  716   52   60]\n",
      " [  39  635   53   59]\n",
      " [  41  539   53   57]\n",
      " [  37  917   62   59]\n",
      " [  36  815   58   56]\n",
      " [  34 1100   69   64]\n",
      " [  36  999   65   64]\n",
      " [  34 1290   43   60]\n",
      " [  32 1212   49   60]\n",
      " [  36 1368   48   60]\n",
      " [  39 1676   67   68]\n",
      " [  38 1586   65   65]\n",
      " [  37 1495   61   59]\n",
      " [  39 1865   79   64]\n",
      " [  41 1779   74   63]\n",
      " [  41 2143   85   81]\n",
      " [  39 2059   80   76]\n",
      " [  37 1961   73   69]\n",
      " [  43 2351  112   77]\n",
      " [  42 2255  101   74]\n",
      " [  44 2620   75   75]\n",
      " [  46 2527   74   74]\n",
      " [  44 2433   74   71]\n",
      " [  41 2816   59   72]\n",
      " [  42 2725   58   70]\n",
      " [  36 3091   67   65]\n",
      " [  37 2988   66   62]\n",
      " [  39 2922   61   59]\n",
      " [  36 3283   79   69]\n",
      " [  37 3182   72   65]\n",
      " [  34 3581   42   61]\n",
      " [  32 3488   47   58]\n",
      " [  34 3371   55   62]\n",
      " [  37 3775  105   69]\n",
      " [  36 3672   91   64]]\n",
      "Disc probability of real sample: 0.011538997292518616\n",
      "A fake sample: [[  74  560   47   50]\n",
      " [  75 1292   40   45]\n",
      " [  74 2432   26   43]\n",
      " [  63 3383    0   46]]\n",
      "Disc probability of fake sample: 0.0346505269408226\n",
      "An interpolated sample: [[  51  409   42   58]\n",
      " [  52  329   44   58]\n",
      " [  49  691   51   59]\n",
      " [  51  612   51   59]\n",
      " [  50  887   53   50]\n",
      " [  45 1069   46   55]\n",
      " [  37 1004   44   55]\n",
      " [  44 1295   42   58]\n",
      " [  43 1245   46   58]\n",
      " [  51 1630   45   56]\n",
      " [  50 1566   46   55]\n",
      " [  51 1829   79   66]\n",
      " [  53 2104   51   71]\n",
      " [  51 2057   51   70]\n",
      " [  54 2312   85   70]\n",
      " [  55 2577   58   68]\n",
      " [  57 2520   58   68]\n",
      " [  53 2775   45   68]\n",
      " [  49 3039   37   58]\n",
      " [  38 2982   40   55]\n",
      " [  49 3259   60   59]\n",
      " [  44 3534   26   56]\n",
      " [  43 3469   31   56]\n",
      " [  49 3753   75   62]\n",
      " [  49 3651   67   59]]\n",
      "Disc probability of interpolated sample: 0.0064924657344818115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   3%|█▌                                                 | 8003/255540 [02:34<1:27:48, 46.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 8000\n",
      "Tot disc loss: 6.96061 partial_disc_error: 0.004716861993074417 grad_error: 6.95589\n",
      "Tot gen loss: -0.07353 partial_gen_error: -0.07767950743436813 gen_error_fm: 0.004149934276938438\n",
      "A real sample: [[   59   162    63    88]\n",
      " [   35    36    72    75]\n",
      " [   71   106    71    90]\n",
      " [   32    43    68    69]\n",
      " [   41    47    72    72]\n",
      " [   51   311    60    85]\n",
      " [   22   435    62    70]\n",
      " [   63   541    94   105]\n",
      " [   34   690   127    96]\n",
      " [   59   710   101   102]\n",
      " [   71   647    72    95]\n",
      " [   59   636    71    85]\n",
      " [   71   619    61    81]\n",
      " [   88   675    60    82]\n",
      " [   88   781   190   114]\n",
      " [   58   960   124    92]\n",
      " [   88   996    38    96]\n",
      " [   34  1102    50    74]\n",
      " [   70  1151    42    84]\n",
      " [   30  1109    46    63]\n",
      " [   39  1093    51    66]\n",
      " [   50  1376    53    86]\n",
      " [   62  1366    48    86]\n",
      " [   54  1670    40    79]\n",
      " [   66  1667    38    81]\n",
      " [   10  1731   117    85]\n",
      " [   22  1718   114    90]\n",
      " [   54  1763   124   101]\n",
      " [   66  1725    93    99]\n",
      " [   88  1789    90   102]\n",
      " [   88  1750    56    84]\n",
      " [   32  2135    67    78]\n",
      " [   41  2136    66    80]\n",
      " [   38  2111    62    73]\n",
      " [   53  2290    72    85]\n",
      " [   65  2294    64    86]\n",
      " [   46  2483    47    77]\n",
      " [   58  2484    48    82]\n",
      " [   65  2880    82    82]\n",
      " [   15  2986   257    78]\n",
      " [   27  2991   238    82]\n",
      " [   53  2986   158    88]\n",
      " [   65  2989   115    88]\n",
      " [   88  3081   112    95]\n",
      " [   88  3046    60    74]\n",
      " [   88  3016    43    64]\n",
      " [   65  2968    58    70]\n",
      " [   88  2964    37    63]\n",
      " [   90  3162 17747    69]\n",
      " [   88  3120   224    64]\n",
      " [   30  3519    89    70]\n",
      " [   39  3529    80    73]\n",
      " [   51  3823    74    68]\n",
      " [   63  3820    62    71]\n",
      " [   90  3687    84    76]]\n",
      "Disc probability of real sample: 0.06374002993106842\n",
      "A fake sample: [[  75  523   27   31]\n",
      " [  75 1470    0   36]\n",
      " [  88 1742   22   31]\n",
      " [  88 3404   17   44]]\n",
      "Disc probability of fake sample: 0.08201165497303009\n",
      "An interpolated sample: [[  58  151   57   84]\n",
      " [  35   34   65   73]\n",
      " [  70  102   64   86]\n",
      " [  32   46   63   67]\n",
      " [  41   47   66   70]\n",
      " [  51  305   59   83]\n",
      " [  21  429   61   69]\n",
      " [  63  539   84   98]\n",
      " [  34  666  110   90]\n",
      " [  59  699   90   96]\n",
      " [  70  644   66   89]\n",
      " [  58  636   65   81]\n",
      " [  70  613   57   78]\n",
      " [  88  773  154  108]\n",
      " [  58  945  107   88]\n",
      " [  88  988   31   91]\n",
      " [  34 1096   41   70]\n",
      " [  69 1142   36   80]\n",
      " [  30 1105   41   61]\n",
      " [  39 1086   45   64]\n",
      " [  50 1362   50   82]\n",
      " [  62 1354   45   81]\n",
      " [  54 1653   34   75]\n",
      " [  66 1655   33   77]\n",
      " [  21 1734  102   80]\n",
      " [  33 1717  100   84]\n",
      " [  54 1762  107   95]\n",
      " [  65 1725   83   94]\n",
      " [  88 1782   81   96]\n",
      " [  88 1751   52   80]\n",
      " [  32 2120   58   73]\n",
      " [  41 2120   57   76]\n",
      " [  38 2102   55   69]\n",
      " [  53 2282   66   81]\n",
      " [  65 2291   59   82]\n",
      " [  45 2478   45   75]\n",
      " [  58 2484   46   79]\n",
      " [  65 2863   78   79]\n",
      " [  15 2976  174   73]\n",
      " [  27 2988  168   78]\n",
      " [  53 2987  125   84]\n",
      " [  65 2989   95   83]\n",
      " [  88 3072   94   90]\n",
      " [  88 3036   53   71]\n",
      " [  88 3005   39   61]\n",
      " [  65 2965   53   68]\n",
      " [  90 3167  695   67]\n",
      " [  88 3120  188   63]\n",
      " [  30 3512   78   68]\n",
      " [  39 3521   71   72]\n",
      " [  51 3807   68   67]\n",
      " [  63 3808   57   69]\n",
      " [  90 3681   75   73]]\n",
      "Disc probability of interpolated sample: 0.061111100018024445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   3%|█▋                                                 | 8506/255540 [02:44<1:13:10, 56.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 8500\n",
      "Tot disc loss: 4.25107 partial_disc_error: 0.04143305867910385 grad_error: 4.20964\n",
      "Tot gen loss: -0.01726 partial_gen_error: -0.021664544939994812 gen_error_fm: 0.00440598838031292\n",
      "A real sample: [[  88  618  227   69]\n",
      " [  53 1101  413   50]\n",
      " [  25 1025  254   36]\n",
      " [  88 1219  175   82]\n",
      " [  41 1541  359   58]\n",
      " [  88 1440  238   80]\n",
      " [  32 1796  114   23]\n",
      " [  44 1809  102   34]\n",
      " [  53 2002   76   53]\n",
      " [  41 2369   83   46]\n",
      " [  53 2193   75   51]\n",
      " [  32 2543  144   33]\n",
      " [  44 2538  123   43]\n",
      " [  29 2868  470   41]\n",
      " [  51 2862  257   53]\n",
      " [  53 2677  193   53]\n",
      " [  41 3041   58   36]\n",
      " [  88 3118   55   59]\n",
      " [  88 3009   51   56]\n",
      " [  32 3226  152   39]\n",
      " [  44 3229  136   48]\n",
      " [  49 3310  118   53]\n",
      " [  88 3299  102   67]\n",
      " [  88 3225   76   64]\n",
      " [  49 3502  160   61]\n",
      " [  32 3818   89   33]\n",
      " [  44 3804   84   42]\n",
      " [  41 3653   85   42]]\n",
      "Disc probability of real sample: -0.02146800234913826\n",
      "A fake sample: [[  88  528   16   35]\n",
      " [  88  970    0   39]\n",
      " [  74 3388   21   52]]\n",
      "Disc probability of fake sample: 0.06521977484226227\n",
      "An interpolated sample: [[  88  601  137   62]\n",
      " [  65 1077  154   48]\n",
      " [  37 1025  127   36]\n",
      " [  88 1227  123   74]\n",
      " [  41 1528  166   53]\n",
      " [  88 1440  135   72]\n",
      " [  43 1796   90   25]\n",
      " [  55 1800   83   35]\n",
      " [  52 2003   62   49]\n",
      " [  53 2354   73   47]\n",
      " [  64 2200   66   51]\n",
      " [  43 2541  115   35]\n",
      " [  55 2526  102   43]\n",
      " [  41 2834  244   42]\n",
      " [  63 2816  178   51]\n",
      " [  41 2999   36   33]\n",
      " [  88 3091   37   54]\n",
      " [  43 3213  114   38]\n",
      " [  43 3215  105   45]\n",
      " [  61 3293   91   49]\n",
      " [  88 3274   81   62]\n",
      " [  49 3481  105   59]\n",
      " [  43 3787   70   33]\n",
      " [  55 3776   68   42]]\n",
      "Disc probability of interpolated sample: -0.004269234836101532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   4%|█▊                                                 | 9009/255540 [02:53<1:12:38, 56.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 9000\n",
      "Tot disc loss: 4.95054 partial_disc_error: 0.01978258043527603 grad_error: 4.93076\n",
      "Tot gen loss: -0.02503 partial_gen_error: -0.029292702674865723 gen_error_fm: 0.004259233828634024\n",
      "A real sample: [[  53  223   32   81]\n",
      " [  41  149   39   72]\n",
      " [  17   56   41   58]\n",
      " [  29   47   50   65]\n",
      " [  39  422   41   83]\n",
      " [  15  345   48   68]\n",
      " [  27  327   48   69]\n",
      " [  38  698   30   83]\n",
      " [  14  622   37   68]\n",
      " [  26  576   40   70]\n",
      " [  51  534   40   77]\n",
      " [  15  902   33   79]\n",
      " [  27  892   37   82]\n",
      " [  50  776   39   86]\n",
      " [  12 1163   48   84]\n",
      " [  24 1158   49   85]\n",
      " [  51 1072   52   90]\n",
      " [  39  991   48   78]\n",
      " [  48 1332   60   78]\n",
      " [  36 1256   56   67]\n",
      " [  43 1667   60   94]\n",
      " [  31 1570   68   85]\n",
      " [  19 1474   70   77]\n",
      " [  43 1477   69   83]\n",
      " [  88 1629   77   99]\n",
      " [  88 1586   48   82]\n",
      " [  88 1528   40   67]\n",
      " [  43 1853   36   71]\n",
      " [  31 1765   40   63]\n",
      " [  43 2148   28   81]\n",
      " [  19 2058   39   69]\n",
      " [  31 2015   44   73]\n",
      " [  31 1951   48   70]\n",
      " [  88 2067   52   88]\n",
      " [  19 2329   29   64]\n",
      " [  31 2313   34   70]\n",
      " [  55 2224   39   79]\n",
      " [  24 2595   36   75]\n",
      " [  55 2498   39   85]\n",
      " [  36 2555   37   71]\n",
      " [  43 2475   51   75]\n",
      " [  26 2874   33   86]\n",
      " [  38 2870   33   87]\n",
      " [  60 2798   38   91]\n",
      " [  48 2687   39   80]\n",
      " [  62 3041   72   86]\n",
      " [  50 2973   65   75]\n",
      " [  63 3307   42  101]\n",
      " [  51 3239   43   89]\n",
      " [  27 3133   44   71]\n",
      " [  39 3126   52   78]\n",
      " [  65 3555   45  100]\n",
      " [  53 3485   47   89]\n",
      " [  29 3394   47   72]\n",
      " [  41 3385   54   78]\n",
      " [  55 3802  103   95]\n",
      " [  31 3699  116   83]\n",
      " [  43 3704   92   82]\n",
      " [  67 3713   79   88]\n",
      " [  88 3812   85   94]\n",
      " [  88 3770   54   78]\n",
      " [  88 3728   41   63]\n",
      " [  88 3718   40   67]]\n",
      "Disc probability of real sample: -0.04205813258886337\n",
      "A fake sample: [[  78 1440    7   32]\n",
      " [  74 3397   16   50]]\n",
      "Disc probability of fake sample: 0.008624470792710781\n",
      "An interpolated sample: [[  75   99   27   57]\n",
      " [  62  585   14   38]\n",
      " [  78  989    0   59]\n",
      " [  79 1453    0   36]\n",
      " [  76 1458    5   38]\n",
      " [  49 1996    0   16]\n",
      " [  74 2229   54   57]\n",
      " [  72 2496   35   47]\n",
      " [  74 2716   35   44]\n",
      " [  88 3206   34   54]\n",
      " [  74 3422    9   56]\n",
      " [  76 3676   34   58]\n",
      " [  76 3624   33   56]]\n",
      "Disc probability of interpolated sample: 0.05568602681159973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   4%|█▉                                                 | 9506/255540 [03:02<1:16:46, 53.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 9500\n",
      "Tot disc loss: 2.46314 partial_disc_error: -0.024201488122344017 grad_error: 2.48735\n",
      "Tot gen loss: 0.01072 partial_gen_error: 0.006407635752111673 gen_error_fm: 0.00431626895442605\n",
      "A real sample: [[  88  213   72   62]\n",
      " [  88  284  143  108]\n",
      " [  88  240  103   98]\n",
      " [  31  556  412   67]\n",
      " [  40  538  257   70]\n",
      " [  24  537  249   64]\n",
      " [  36  534  189   71]\n",
      " [  48  524  138   73]\n",
      " [  88  554   89   79]\n",
      " [  88  801  104   96]\n",
      " [  88  761   82   88]\n",
      " [  88  752   61   77]\n",
      " [  40 1190  170   39]\n",
      " [  55 1153  130   48]\n",
      " [  88 1163  127   61]\n",
      " [  88 1087   85   57]\n",
      " [  88 1427   72   85]\n",
      " [  88 1378   60   78]\n",
      " [  88 1332   49   71]\n",
      " [  88 1268   42   67]\n",
      " [  56 1467  128   73]\n",
      " [  36 1518  120   64]\n",
      " [  88 1597  113   86]\n",
      " [  88 1574   71   77]\n",
      " [  88 1555   64   74]\n",
      " [  88 1524   39   60]\n",
      " [  56 1870   98   68]\n",
      " [  57 1778   98   69]\n",
      " [  41 1778   85   59]\n",
      " [  88 1898   85   80]\n",
      " [  88 1845   67   74]\n",
      " [  88 1803   45   64]\n",
      " [  88 1789   39   64]\n",
      " [  45 2042  165   56]\n",
      " [  57 1964  166   66]\n",
      " [  61 2116  111   65]\n",
      " [  88 2142  114   80]\n",
      " [  62 2070   90   67]\n",
      " [  88 2106   70   71]\n",
      " [  88 2081   45   64]\n",
      " [  88 2082   47   63]\n",
      " [  88 2032   35   61]\n",
      " [  88 2032   33   61]\n",
      " [  50 2365  151   43]\n",
      " [  65 2325  120   51]\n",
      " [  88 2353  108   59]\n",
      " [  88 2318   78   56]\n",
      " [  62 2243   67   49]\n",
      " [  88 2458   82  102]\n",
      " [  88 2440   67   94]\n",
      " [  88 2424   51   82]\n",
      " [  35 2671   50   46]\n",
      " [  64 2863   52   64]\n",
      " [  62 2802   61   67]\n",
      " [  64 2724   63   68]\n",
      " [  88 2766   68   79]\n",
      " [  88 2715   36   63]\n",
      " [  88 2695   33   57]\n",
      " [  88 2691   35   62]\n",
      " [  59 3057   72   63]\n",
      " [  47 2915   69   56]\n",
      " [  60 3026   86   67]\n",
      " [  62 2948   87   72]\n",
      " [  88 2955   81   81]\n",
      " [  88 2926   44   67]\n",
      " [  88 2909   33   59]\n",
      " [  88 2907   39   64]\n",
      " [  59 3201  170   67]\n",
      " [  41 3183  146   58]\n",
      " [  88 3252  177   83]\n",
      " [  88 3240  116   80]\n",
      " [  88 3197   97   79]\n",
      " [  88 3146   50   63]\n",
      " [  60 3134   47   73]\n",
      " [  88 3161   44   64]\n",
      " [  88 3156   35   64]\n",
      " [  54 3579  107   56]\n",
      " [  40 3499  115   51]\n",
      " [  55 3475   88   57]\n",
      " [  57 3435   77   59]\n",
      " [  88 3575   90   75]\n",
      " [  88 3532   53   61]\n",
      " [  88 3489   42   65]\n",
      " [  43 3774   91   45]\n",
      " [  55 3689   93   54]\n",
      " [  60 3775   79   56]\n",
      " [  88 3794   88   73]\n",
      " [  88 3771   75   72]\n",
      " [  88 3724   42   58]\n",
      " [  88 3710   40   60]\n",
      " [  88 3718   40   59]\n",
      " [  88 3681   38   65]\n",
      " [  88 3679   30   59]]\n",
      "Disc probability of real sample: 0.002914383076131344\n",
      "A fake sample: [[  75 1444   21   64]\n",
      " [  88 1992   16   42]\n",
      " [  88 2485   19   23]]\n",
      "Disc probability of fake sample: 0.03343901038169861\n",
      "An interpolated sample: [[  88  538   21   36]\n",
      " [  75 1440   20   64]\n",
      " [  88 1994   15   41]\n",
      " [  88 2487   19   25]\n",
      " [  74 3361    9   45]]\n",
      "Disc probability of interpolated sample: 0.035030823200941086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   4%|█▉                                                | 10004/255540 [03:11<1:21:53, 49.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 10000\n",
      "Tot disc loss: 4.16154 partial_disc_error: -0.035921450704336166 grad_error: 4.19746\n",
      "Tot gen loss: 0.01440 partial_gen_error: 0.0100101288408041 gen_error_fm: 0.004394823685288429\n",
      "A real sample: [[  55  191   78   67]\n",
      " [  49  186   70   63]\n",
      " [  52  360  127   60]\n",
      " [  43  576   67   64]\n",
      " [  49  569   62   66]\n",
      " [  46  727   77   56]\n",
      " [  27 1148  423   43]\n",
      " [  46  969  265   52]\n",
      " [  42  989  219   53]\n",
      " [  88 1135  161   72]\n",
      " [  88 1058  102   67]\n",
      " [  88 1027   63   57]\n",
      " [  45 1373  252   45]\n",
      " [  36 1378  185   42]\n",
      " [  88 1352  163   64]\n",
      " [  33 1570   78   64]\n",
      " [  88 1677   69   88]\n",
      " [  88 1579   67   83]\n",
      " [  88 1506   53   77]\n",
      " [  29 1757  131   47]\n",
      " [  88 1881  110   75]\n",
      " [  88 1749   90   70]\n",
      " [  57 2139  142   57]\n",
      " [  39 2128  137   50]\n",
      " [  30 1985  119   45]\n",
      " [  88 2134  102   70]\n",
      " [  88 2072   77   66]\n",
      " [  88 2026   50   56]\n",
      " [  36 2340  179   41]\n",
      " [  42 2171  134   41]\n",
      " [  88 2295  164   68]\n",
      " [  48 2197  102   49]\n",
      " [  88 2216   86   65]\n",
      " [  88 2202   47   53]\n",
      " [  32 2533   96   50]\n",
      " [  88 2545   82   74]\n",
      " [  88 2464   77   71]\n",
      " [  88 2422   62   68]\n",
      " [  33 2711   77   75]\n",
      " [  88 2785   71   98]\n",
      " [  88 2682   61   89]\n",
      " [  39 3099   67   45]\n",
      " [  39 2944   70   45]\n",
      " [  42 2891   65   48]\n",
      " [  88 3056   62   68]\n",
      " [  48 2968   56   51]\n",
      " [  88 2976   43   62]\n",
      " [  43 2962   61   56]\n",
      " [  88 3120   71   72]\n",
      " [  51 3311   74   59]\n",
      " [  36 3320   68   54]\n",
      " [  88 3334   59   71]\n",
      " [  88 3303   49   67]\n",
      " [  33 3313   91   59]\n",
      " [  88 3379  154  117]\n",
      " [  88 3496  113  108]\n",
      " [  88 3431   79   94]\n",
      " [  45 3698  143   59]\n",
      " [  30 3682  142   54]\n",
      " [  36 3740  120   55]\n",
      " [  88 3794  104   77]\n",
      " [  88 3732   77   72]\n",
      " [  88 3694   49   60]]\n",
      "Disc probability of real sample: -0.03158585727214813\n",
      "A fake sample: [[  85 2477   29   29]\n",
      " [  74 3394   14   47]]\n",
      "Disc probability of fake sample: 0.01136133261024952\n",
      "An interpolated sample: [[  76   91   33   57]\n",
      " [  65  558   35   41]\n",
      " [  64 1021   14   43]\n",
      " [  67 1000   19   47]\n",
      " [  68 1241   29   35]\n",
      " [  67 1445    0   50]\n",
      " [  88 1515    7   59]\n",
      " [  76 1735   22   44]\n",
      " [  64 2005    7   10]\n",
      " [  65 2040   14   17]\n",
      " [  73 2295   86   51]\n",
      " [  74 2211   71   47]\n",
      " [  75 2512   45   34]\n",
      " [  88 2454   44   43]\n",
      " [  64 2718   52   42]\n",
      " [  67 2906    0   30]\n",
      " [  66 2962    0   33]\n",
      " [  88 3125   62   55]\n",
      " [  76 3147   53   48]\n",
      " [  74 3391   22   64]\n",
      " [  78 3658   32   44]\n",
      " [  65 3631   33   42]]\n",
      "Disc probability of interpolated sample: -0.01363905519247055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   4%|██                                                | 10507/255540 [03:20<1:12:02, 56.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 10500\n",
      "Tot disc loss: 2.91144 partial_disc_error: -0.01821606419980526 grad_error: 2.92965\n",
      "Tot gen loss: 0.01640 partial_gen_error: 0.011718472465872765 gen_error_fm: 0.004681393504142761\n",
      "A real sample: [[  35  178   66   60]\n",
      " [  32  186   76   62]\n",
      " [  56  204   67   71]\n",
      " [  53  178   57   65]\n",
      " [  37  152   66   60]\n",
      " [  53  368   66   72]\n",
      " [  61  255   59   72]\n",
      " [  18  639   89   70]\n",
      " [  66  646   74   90]\n",
      " [  88  674   74   93]\n",
      " [  33  950   61   58]\n",
      " [  30  953   64   57]\n",
      " [  54  898   76   73]\n",
      " [  37  882   73   64]\n",
      " [  88  864   64   79]\n",
      " [  88  805   40   67]\n",
      " [  88  771   35   56]\n",
      " [  54 1098   60   75]\n",
      " [  57  965   59   73]\n",
      " [  61 1035   53   70]\n",
      " [  56 1363   56   72]\n",
      " [  25 1359   66   59]\n",
      " [  65 1379   56   74]\n",
      " [  61 1390   51   69]\n",
      " [  88 1396   51   77]\n",
      " [  88 1370   34   63]\n",
      " [  88 1344   44   67]\n",
      " [  35 1619   31   59]\n",
      " [  57 1617   39   73]\n",
      " [  41 1593   40   64]\n",
      " [  65 1611   46   76]\n",
      " [  37 1586   57   66]\n",
      " [  61 1595   66   82]\n",
      " [  43 1531   61   68]\n",
      " [  86 1551   40   70]\n",
      " [  68 1900   35   82]\n",
      " [  56 1811   40   75]\n",
      " [  25 1815   43   58]\n",
      " [  65 1808   52   79]\n",
      " [  69 1712   44   73]\n",
      " [  61 1797   52   74]\n",
      " [  30 2065   60   53]\n",
      " [  67 2087   61   72]\n",
      " [  66 2084   55   69]\n",
      " [  88 2133   53   75]\n",
      " [  88 2089   46   70]\n",
      " [  88 2053   32   59]\n",
      " [  33 2335   45   66]\n",
      " [  57 2385   52   80]\n",
      " [  42 2329   51   70]\n",
      " [  54 2305   50   73]\n",
      " [  37 2299   60   66]\n",
      " [  88 2302   52   80]\n",
      " [  54 2504   83   78]\n",
      " [  61 2419   72   77]\n",
      " [  25 2787   67   75]\n",
      " [  88 2847   62   99]\n",
      " [  73 2776   47   84]\n",
      " [  47 3068   28   62]\n",
      " [  44 3079   39   64]\n",
      " [  68 3088   37   73]\n",
      " [  41 3034   40   60]\n",
      " [  37 3046   52   62]\n",
      " [  61 3058   66   79]\n",
      " [  88 3034   52   74]\n",
      " [  71 3159  114   73]\n",
      " [  61 3249   96   70]\n",
      " [  30 3494   36   63]\n",
      " [  88 3589   36   88]\n",
      " [  88 3558   34   82]\n",
      " [  88 3522   30   75]\n",
      " [  73 3483   32   69]\n",
      " [  45 3751   47   62]\n",
      " [  42 3782   53   62]\n",
      " [  66 3778   55   74]\n",
      " [  37 3753   53   59]\n",
      " [  61 3756   53   69]\n",
      " [  88 3712   43   71]]\n",
      "Disc probability of real sample: 0.029315918684005737\n",
      "A fake sample: [[  88  543   29   40]\n",
      " [  74 3377   24   53]]\n",
      "Disc probability of fake sample: -0.003935687243938446\n",
      "An interpolated sample: [[  57  120   32   50]\n",
      " [  55  133   37   53]\n",
      " [  66  150   36   56]\n",
      " [  64  328   66   61]\n",
      " [  53  605   56   59]\n",
      " [  77  604   51   69]\n",
      " [  56  862   48   46]\n",
      " [  42  861   50   44]\n",
      " [  65  846   55   56]\n",
      " [  50  821   51   52]\n",
      " [  53 1031   21   59]\n",
      " [  68  995   26   61]\n",
      " [  67 1302   27   48]\n",
      " [  51 1250   33   45]\n",
      " [  65 1336   33   53]\n",
      " [  62 1344   31   52]\n",
      " [  56 1536    0   50]\n",
      " [  67 1553   12   63]\n",
      " [  65 1560   14   56]\n",
      " [  64 1570   21   62]\n",
      " [  50 1545   29   57]\n",
      " [  78 1826   14   59]\n",
      " [  66 1755   19   54]\n",
      " [  50 1788   19   44]\n",
      " [  64 1785   29   58]\n",
      " [  53 2021   37   38]\n",
      " [  78 2017   39   50]\n",
      " [  77 2057   37   50]\n",
      " [  86 2069   35   55]\n",
      " [  54 2290   51   65]\n",
      " [  79 2289   52   72]\n",
      " [  65 2322   44   64]\n",
      " [  64 2298   44   64]\n",
      " [  65 2513   50   55]\n",
      " [  50 2742   50   57]\n",
      " [  76 2752   48   68]\n",
      " [  56 2978    0   47]\n",
      " [  55 3031    0   50]\n",
      " [  65 3073    8   58]\n",
      " [  65 3028   14   55]\n",
      " [  81 3140   69   66]\n",
      " [  52 3441   20   57]\n",
      " [  88 3530   24   73]\n",
      " [  88 3514   21   67]\n",
      " [  67 3725   29   56]\n",
      " [  65 3708   31   57]\n",
      " [  77 3727   33   61]\n",
      " [  62 3709   32   54]]\n",
      "Disc probability of interpolated sample: 0.03330165892839432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   4%|██▏                                               | 11005/255540 [03:29<1:14:44, 54.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 11000\n",
      "Tot disc loss: 5.68721 partial_disc_error: -0.011161601170897484 grad_error: 5.69837\n",
      "Tot gen loss: 0.01833 partial_gen_error: 0.014004284515976906 gen_error_fm: 0.004327850416302681\n",
      "A real sample: [[  32  187   40   34]\n",
      " [  39  182   42   40]\n",
      " [  36  159   42   39]\n",
      " [  88  450   63   76]\n",
      " [  53  542  181   66]\n",
      " [  25  499  153   52]\n",
      " [  88  589  148   80]\n",
      " [  88  552   85   72]\n",
      " [  88  526   72   70]\n",
      " [  32  882   63   43]\n",
      " [  55  891   61   57]\n",
      " [  41  849   64   51]\n",
      " [  37  847   68   52]\n",
      " [  56 1010  167   81]\n",
      " [  60 1143  129   81]\n",
      " [  32 1434   58   69]\n",
      " [  56 1425   58   80]\n",
      " [  37 1405   56   66]\n",
      " [  88 1395   57   84]\n",
      " [  61 1292   51   71]\n",
      " [  53 1559   67   46]\n",
      " [  88 1674   67   61]\n",
      " [  41 1446   56   39]\n",
      " [  18 1712  154   61]\n",
      " [  51 1773  142   77]\n",
      " [  33 1721  126   71]\n",
      " [  88 1841   93   84]\n",
      " [  88 1796   72   77]\n",
      " [  88 1937   99   56]\n",
      " [  30 2097  107   37]\n",
      " [  57 2065   84   50]\n",
      " [  39 2069   71   40]\n",
      " [  37 2051   72   44]\n",
      " [  58 2219  198   80]\n",
      " [  60 2358  149   79]\n",
      " [  58 2632  144   85]\n",
      " [  61 2496  117   81]\n",
      " [  34 2650   33   60]\n",
      " [  30 2651   39   59]\n",
      " [  51 2728   44   70]\n",
      " [  37 2687   50   64]\n",
      " [  19 2909  104   69]\n",
      " [  63 3046   90   89]\n",
      " [  51 2942   99   83]\n",
      " [  88 2982   89   95]\n",
      " [  88 2933   71   88]\n",
      " [  88 2922   40   70]\n",
      " [  88 2928   31   58]\n",
      " [  34 3208  354   56]\n",
      " [  31 3212  298   58]\n",
      " [  61 3344  209   72]\n",
      " [  39 3225  164   61]\n",
      " [  88 3324  142   83]\n",
      " [  88 3266   78   68]\n",
      " [  61 3195   53   66]\n",
      " [  88 3239   51   64]\n",
      " [  36 3483   97   67]\n",
      " [  88 3574   89   90]\n",
      " [  88 3552   74   85]\n",
      " [  60 3516   64   70]\n",
      " [  88 3507   58   76]\n",
      " [  88 3484   34   62]\n",
      " [  45 3504   53   56]\n",
      " [  88 3609   56   92]\n",
      " [  39 3784   70   74]\n",
      " [  37 3791   51   66]\n",
      " [  49 3774   60   74]\n",
      " [  88 3821   58   87]\n",
      " [  88 3779   33   68]\n",
      " [  51 3673   52   61]\n",
      " [  88 3756   35   66]\n",
      " [  88 3721   39   66]]\n",
      "Disc probability of real sample: -0.04602298140525818\n",
      "A fake sample: [[  88  548   46   55]\n",
      " [  88  970    0   44]\n",
      " [  74 1440    9   54]]\n",
      "Disc probability of fake sample: -0.02243758738040924\n",
      "An interpolated sample: [[  65  122   29   45]\n",
      " [  77  545   76   59]\n",
      " [  63  492   66   53]\n",
      " [  53  765   19   27]\n",
      " [  80  971   31   59]\n",
      " [  65 1306   30   45]\n",
      " [  67 1273   33   49]\n",
      " [  76 1450    0   43]\n",
      " [  88 1547    8   50]\n",
      " [  64 1738   50   55]\n",
      " [  75 1694   48   58]\n",
      " [  74 1920   17   24]\n",
      " [  54 2021   21   19]\n",
      " [  77 2239   95   64]\n",
      " [  78 2556   50   44]\n",
      " [  67 2654   34   44]\n",
      " [  53 2665   33   36]\n",
      " [  43 2887   10   40]\n",
      " [  64 2983   15   53]\n",
      " [  74 2970   18   54]\n",
      " [  67 3184   90   54]\n",
      " [  65 3180   81   53]\n",
      " [  75 3247   72   55]\n",
      " [  60 3454    0   47]\n",
      " [  88 3480    9   61]\n",
      " [  88 3465    9   57]\n",
      " [  75 3632   38   64]\n",
      " [  63 3638   39   58]\n",
      " [  62 3735   33   52]\n",
      " [  75 3730   36   58]]\n",
      "Disc probability of interpolated sample: -0.039662737399339676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   5%|██▎                                               | 11509/255540 [03:38<1:13:04, 55.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 11500\n",
      "Tot disc loss: 5.28134 partial_disc_error: -0.013156702741980553 grad_error: 5.29450\n",
      "Tot gen loss: 0.00867 partial_gen_error: 0.004237948916852474 gen_error_fm: 0.004433268681168556\n",
      "A real sample: [[  58  201   62   74]\n",
      " [  57  133   61   71]\n",
      " [  58   28   63   70]\n",
      " [  58  388   92   73]\n",
      " [  63  304   81   74]\n",
      " [  56  685   38   78]\n",
      " [  58  599   44   78]\n",
      " [  38  652   45   66]\n",
      " [  56  516   51   74]\n",
      " [  41  499   56   67]\n",
      " [  58  952   46   79]\n",
      " [  34  864   54   67]\n",
      " [  56  858   52   74]\n",
      " [  58  786   51   72]\n",
      " [  58 1155   99   83]\n",
      " [  55 1071   92   79]\n",
      " [  39 1038   83   67]\n",
      " [  53 1422   78   77]\n",
      " [  55 1329   72   75]\n",
      " [  63 1251   66   73]\n",
      " [  51 1604   82   75]\n",
      " [  62 1505   71   76]\n",
      " [  58 1874   72   83]\n",
      " [  50 1796   71   78]\n",
      " [  46 1901   73   75]\n",
      " [  60 1932   76   79]\n",
      " [  56 2048   72   76]\n",
      " [  48 1992   63   65]\n",
      " [  44 2355   72   71]\n",
      " [  55 2259   67   74]\n",
      " [  43 2535   70   72]\n",
      " [  51 2618   66   76]\n",
      " [  53 2434   64   72]\n",
      " [  41 2726   74   70]\n",
      " [  50 2807   67   73]\n",
      " [  38 3089   54   69]\n",
      " [  39 2907   54   66]\n",
      " [  48 2994   48   64]\n",
      " [  45 3312  311   61]\n",
      " [  46 3185  227   61]\n",
      " [  36 3312  168   54]\n",
      " [  24 3545  169   45]\n",
      " [  27 3751  158   56]]\n",
      "Disc probability of real sample: 0.02397647686302662\n",
      "A fake sample: [[  74 2449   28   40]\n",
      " [  88 3390    7   50]]\n",
      "Disc probability of fake sample: -0.022721320390701294\n",
      "An interpolated sample: [[  76   69   27   51]\n",
      " [  88  338   43   46]\n",
      " [  77  585   25   40]\n",
      " [  75  568   25   41]\n",
      " [  77  772   40   43]\n",
      " [  67  974    4   41]\n",
      " [  75 1294   84   70]\n",
      " [  77 1750   45   48]\n",
      " [  76 1923    9   41]\n",
      " [  63 2478   34   49]\n",
      " [  76 2424   35   55]\n",
      " [  51 2930    0   52]\n",
      " [  77 3225   52   54]\n",
      " [  74 3411   17   48]]\n",
      "Disc probability of interpolated sample: 0.03322688862681389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   5%|██▎                                               | 12007/255540 [03:47<1:17:25, 52.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 12000\n",
      "Tot disc loss: 4.52656 partial_disc_error: 0.004021347500383854 grad_error: 4.52254\n",
      "Tot gen loss: -0.00223 partial_gen_error: -0.0066478922963142395 gen_error_fm: 0.004418834578245878\n",
      "A real sample: [[  20  229   61   49]\n",
      " [  27  128   66   53]\n",
      " [  48  207   60   62]\n",
      " [  51  134   60   63]\n",
      " [  88  200   62   78]\n",
      " [  88  151   36   62]\n",
      " [  88  128   42   63]\n",
      " [  44  462   54   68]\n",
      " [  28  445   53   60]\n",
      " [  90  413   83   85]\n",
      " [  90  329   51   70]\n",
      " [  88  266   41   72]\n",
      " [  40  568   46   68]\n",
      " [  36  555   45   64]\n",
      " [  21  877   94   58]\n",
      " [  47  865   96   73]\n",
      " [  28  831   94   60]\n",
      " [  88  954   96   88]\n",
      " [  51  780   72   68]\n",
      " [  88  867   65   77]\n",
      " [  88  818   43   68]\n",
      " [  43 1152  182   71]\n",
      " [  28 1148  150   63]\n",
      " [  88 1009  145   88]\n",
      " [  40 1266   52   64]\n",
      " [  37 1246   51   62]\n",
      " [  20 1654  108   44]\n",
      " [  48 1632   97   58]\n",
      " [  27 1516   92   48]\n",
      " [  51 1533   83   60]\n",
      " [  88 1596   76   72]\n",
      " [  88 1752  100   93]\n",
      " [  88 1712   79   86]\n",
      " [  88 1717   59   75]\n",
      " [  40 2088   36   47]\n",
      " [  44 1948   41   49]\n",
      " [  28 1974   46   43]\n",
      " [  36 2035   53   54]\n",
      " [  27 2340  122   46]\n",
      " [  49 2313  102   56]\n",
      " [  18 2557  102   41]\n",
      " [  88 2627   90   74]\n",
      " [  52 2644  229   78]\n",
      " [  88 2785  170   93]\n",
      " [  88 2699  127   85]\n",
      " [  88 2652   92   79]\n",
      " [  44 2996   82   47]\n",
      " [  28 2974   84   42]\n",
      " [  45 2898   84   52]\n",
      " [  27 3282   88   49]\n",
      " [  42 3219   87   57]\n",
      " [  43 3147   82   56]\n",
      " [  88 3303   74   73]\n",
      " [  37 3148   62   52]\n",
      " [  20 3425  142   59]\n",
      " [  51 3526  109   74]\n",
      " [  88 3512  149   92]\n",
      " [  48 3387   96   69]\n",
      " [  88 3409   84   83]\n",
      " [  88 3394   47   67]\n",
      " [  42 3791   58   60]\n",
      " [  28 3744   60   53]\n",
      " [  36 3701   58   54]]\n",
      "Disc probability of real sample: 0.009119312278926373\n",
      "A fake sample: [[  88 2469   26   41]\n",
      " [  74 3378    0   47]]\n",
      "Disc probability of fake sample: -0.01652856171131134\n",
      "An interpolated sample: [[  66  131   26   52]\n",
      " [  64   72   27   53]\n",
      " [  74  132   25   54]\n",
      " [  76  323   35   46]\n",
      " [  62  373   35   45]\n",
      " [  64  539   34   46]\n",
      " [  78  763   35   42]\n",
      " [  66  813   37   44]\n",
      " [  64  826   33   40]\n",
      " [  67 1033   28   50]\n",
      " [  65 1274   41   58]\n",
      " [  53 1536   16   26]\n",
      " [  74 1519   20   35]\n",
      " [  87 1749   42   65]\n",
      " [  49 1989    0   19]\n",
      " [  67 1923    0   29]\n",
      " [  75 2252  103   59]\n",
      " [  65 2508   45   43]\n",
      " [  65 2640   45   40]\n",
      " [  54 2914    0   41]\n",
      " [  65 3244   37   43]\n",
      " [  64 3144   38   44]\n",
      " [  64 3392   20   49]\n",
      " [  76 3480   22   59]\n",
      " [  88 3427   26   59]\n",
      " [  63 3716   43   54]]\n",
      "Disc probability of interpolated sample: -0.016573291271924973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   5%|██▍                                               | 12505/255540 [03:56<1:16:30, 52.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 12500\n",
      "Tot disc loss: 7.49022 partial_disc_error: 0.00846124067902565 grad_error: 7.48176\n",
      "Tot gen loss: 0.01027 partial_gen_error: 0.006204515229910612 gen_error_fm: 0.004070363473147154\n",
      "A real sample: [[   19   496   128    77]\n",
      " [   31   482   120    83]\n",
      " [   88   648   113   102]\n",
      " [   45   574    90    82]\n",
      " [   88   601    84    92]\n",
      " [   88   750    50    84]\n",
      " [   58   876    48    69]\n",
      " [   40   828    45    56]\n",
      " [   51  1554   175    71]\n",
      " [   20  1814  1120    52]\n",
      " [   32  1773   438    59]\n",
      " [   44  1768   310    67]\n",
      " [   40  1785   189    63]\n",
      " [   88  1899   164    84]\n",
      " [   49  1765   120    67]\n",
      " [   88  1825    53    75]\n",
      " [   88  2097    91    91]\n",
      " [   88  2065    73    83]\n",
      " [   88  2018    60    75]\n",
      " [   88  1967    50    71]\n",
      " [   23  2709 17747    45]\n",
      " [   35  2689   976    57]\n",
      " [   47  2679   376    65]\n",
      " [   44  2686   206    62]\n",
      " [   40  2707   180    62]\n",
      " [   88  2841   157    83]\n",
      " [   88  2774    44    68]\n",
      " [   88  2965   187   109]\n",
      " [   88  2899   125    99]\n",
      " [   20  3662   181    64]\n",
      " [   32  3647   150    70]\n",
      " [   88  3791   163    95]\n",
      " [   88  3739    95    85]\n",
      " [   88  3694    80    81]\n",
      " [   88  3662    50    67]]\n",
      "Disc probability of real sample: -0.022331535816192627\n",
      "A fake sample: [[  88  513   15   42]\n",
      " [  88 1498    0   29]\n",
      " [  88 1730   17   25]\n",
      " [  88 2892    0   34]]\n",
      "Disc probability of fake sample: 0.026845864951610565\n",
      "An interpolated sample: [[  88  502   16   43]\n",
      " [  88 1502    0   32]\n",
      " [  86 1745   25   23]\n",
      " [  76 2896    0   37]\n",
      " [  75 3648   29   49]]\n",
      "Disc probability of interpolated sample: 0.01324138231575489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   5%|██▍                                               | 12665/255540 [04:00<1:16:46, 52.72it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(train_CGAN)\n\u001b[1;32m      4\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(CGAN)\n\u001b[0;32m----> 5\u001b[0m disc_losses, gen_losses \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainCGAN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Python/TimeStepMusic/python/run.py:134\u001b[0m, in \u001b[0;36mTrainCGAN\u001b[0;34m(events, annotation, metadata)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mprint\u001b[39m(cgan_disc_model)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mprint\u001b[39m(cgan_gen_model)\n\u001b[0;32m--> 134\u001b[0m \u001b[43mtrain_CGAN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcgan_disc_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcgan_gen_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mae_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcgan_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtot_chunks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mCGAN_TOT_CHUNKS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCGAN_LATENT_DIM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCGAN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCGAN_LEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCGAN_BATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAE_LATENT_DIM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mchunk_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCHUNK_LENGTH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_gp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCGAN_LAMBDA_GP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mlambda_fm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCGAN_LAMBDA_FM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mdisc_model_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCGAN_DISC_MODEL_FILE_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mgen_model_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCGAN_GEN_MODEL_FILE_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATA_TYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mexamples_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexamples_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Python/TimeStepMusic/python/train_CGAN.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(disc_model, gen_model, ae_model, train_dataset, tot_chunks, latent_dim, epochs, lr, batch_size, num_channels, chunk_length, lambda_gp, lambda_fm, model_path, disc_model_file, gen_model_file, data_type, examples_path)\u001b[0m\n\u001b[1;32m    177\u001b[0m batch_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m real_batch \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(data_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 181\u001b[0m     disc_error, features_real, partial_disc_error, grad_error \u001b[38;5;241m=\u001b[39m \u001b[43mdisc_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisc_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m                                                                           \u001b[49m\u001b[43mgen_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m                                                                           \u001b[49m\u001b[43mdisc_optim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m                                                                           \u001b[49m\u001b[43mdistribution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m                                                                           \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m                                                                           \u001b[49m\u001b[43mreal_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m                                                                           \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m                                                                           \u001b[49m\u001b[43mlambda_gp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     disc_losses\u001b[38;5;241m.\u001b[39mappend((disc_error, partial_disc_error, grad_error))\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_counter \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m#original paper recommends one gen training every 5 disc\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Python/TimeStepMusic/python/train_CGAN.py:116\u001b[0m, in \u001b[0;36mdisc_train\u001b[0;34m(disc_model, gen_model, disc_optim, distribution, device, real_batch, batch_size, lambda_gp)\u001b[0m\n\u001b[1;32m    111\u001b[0m grad_error \u001b[38;5;241m=\u001b[39m lambda_gp \u001b[38;5;241m*\u001b[39m grad_penalty(disc_model, device, real_batch, \n\u001b[1;32m    112\u001b[0m                                       fake_batch, batch_size)\n\u001b[1;32m    114\u001b[0m disc_error \u001b[38;5;241m=\u001b[39m partial_disc_error \u001b[38;5;241m+\u001b[39m grad_error\n\u001b[0;32m--> 116\u001b[0m \u001b[43mdisc_error\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m disc_optim\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m#update disc_model\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m disc_error\u001b[38;5;241m.\u001b[39mitem(), features_real\u001b[38;5;241m.\u001b[39mdetach(), partial_disc_error\u001b[38;5;241m.\u001b[39mitem(), grad_error\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "importlib.reload(run)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(train_CGAN)\n",
    "importlib.reload(CGAN)\n",
    "disc_losses, gen_losses = run.TrainCGAN(events, annotation, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(run)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(train_CGAN)\n",
    "importlib.reload(CGAN)\n",
    "run.ContinueTrainCGAN(events, annotation, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "025fdd21",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of decoder: tensor([[    -0.127,      0.840,      0.975,      0.140,     -1.857,      0.610],\n",
      "        [    -0.105,      1.321,      0.248,      0.475,      1.224,      0.713],\n",
      "        [     0.298,      1.367,      1.865,      0.450,     -0.617,      0.429],\n",
      "        [     0.039,      1.080,     -0.797,      0.298,      0.941,     -0.672],\n",
      "        [     0.484,      0.362,      0.642,     -1.306,      3.653,     -2.204],\n",
      "        [    -0.145,      0.830,      0.585,      0.236,      1.319,      0.718],\n",
      "        [     0.563,      0.756,      0.106,      0.224,     -0.363,     -0.328],\n",
      "        [    -0.241,      0.887,      1.129,      0.147,      3.030,      0.661],\n",
      "        [     0.027,      0.892,      0.050,      0.263,     -1.330,      0.289],\n",
      "        [    -0.125,      0.412,      0.831,      0.284,     -1.616,      0.425],\n",
      "        [    -0.158,      0.506,      0.590,     -0.011,     -1.686,      0.294],\n",
      "        [    -0.050,      0.743,      0.315,     -0.009,      0.065,      0.082],\n",
      "        [    -0.182,      0.816,      0.206,      0.197,      0.847,      1.016],\n",
      "        [    -0.108,      0.738,      0.556,      0.163,     -0.662,      0.467],\n",
      "        [    -0.140,      0.060,      0.462,     -0.019,     -0.724,      0.296],\n",
      "        [    -0.125,      0.294,      0.324,     -0.042,     -1.271,      0.764],\n",
      "        [    -0.160,      0.329,      0.684,      0.159,      0.004,      0.790],\n",
      "        [    -0.079,      0.803,      0.008,     -0.127,     -0.839,      0.435],\n",
      "        [    -0.140,      0.750,      0.102,      0.112,     -1.605,      0.839],\n",
      "        [     0.096,      0.858,     -0.043,     -0.118,     -0.042,      0.343],\n",
      "        [    -0.093,      0.836,      0.274,      0.188,     -1.224,      0.777],\n",
      "        [     0.020,      0.945,      0.706,      0.115,     -1.056,      0.306],\n",
      "        [     0.675,      0.783,      2.209,      0.034,      1.320,      0.688],\n",
      "        [     0.286,      1.271,      0.556,      0.209,     -0.357,      0.779],\n",
      "        [     0.428,      0.873,      1.525,     -0.375,     -1.365,     -1.070],\n",
      "        [     0.073,      1.089,      1.560,      0.201,     -1.719,      0.239],\n",
      "        [    -0.156,      0.177,      1.408,      0.190,     -0.230,     -0.724],\n",
      "        [    -0.169,      0.362,      0.742,      0.233,     -0.450,      0.391],\n",
      "        [    -0.121,      0.645,     -0.003,     -0.758,      1.680,     -0.993],\n",
      "        [     0.722,      0.467,      0.564,     -1.006,     -1.348,     -1.664],\n",
      "        [    -0.043,      0.943,      1.038,     -0.026,     -1.487,      0.003],\n",
      "        [    -0.152,      0.691,     -0.103,     -0.238,     -1.973,     -0.248],\n",
      "        [    -0.129,      0.647,      0.508,      0.005,     -0.665,      0.920],\n",
      "        [    -0.025,      0.901,      0.086,      0.053,     -1.845,      0.474],\n",
      "        [    -0.144,      0.600,      1.227,      0.104,     -1.119,      0.524],\n",
      "        [    -0.151,      0.438,      0.467,      0.047,     -0.656,      0.673],\n",
      "        [    -0.149,      0.395,      0.610,      0.202,     -0.723,     -0.281],\n",
      "        [     0.255,      0.684,      0.011,     -0.221,     -1.244,      0.150],\n",
      "        [    -0.127,      0.474,      0.280,      0.100,     -0.265,      0.697],\n",
      "        [    -0.119,      0.901,     -0.022,      0.135,     -0.038,      0.909],\n",
      "        [    -0.090,      0.616,      0.468,     -0.307,     -0.924,      0.379],\n",
      "        [    -0.047,      0.810,      0.270,      0.156,     -0.890,      0.858],\n",
      "        [    -0.061,      0.969,     -0.331,      0.244,      0.618,      0.809],\n",
      "        [     0.161,      0.746,      0.128,      0.038,     -2.025,      0.800],\n",
      "        [    -0.003,      0.875,     -0.235,      0.124,     -0.690,      0.929],\n",
      "        [    -0.011,      0.867,      0.338,      0.302,     -1.043,      0.793],\n",
      "        [     1.563,      0.049,      0.842,     -0.024,      0.618,     -1.188],\n",
      "        [     0.193,      0.902,      0.478,      0.097,     -1.269,      0.850],\n",
      "        [    -0.101,      0.294,      0.571,      0.158,     -1.245,      1.021],\n",
      "        [     0.410,      0.665,      0.163,      0.071,     -1.759,      0.775],\n",
      "        [    -0.111,      0.824,      0.386,      0.006,     -1.127,      0.872],\n",
      "        [     0.378,      1.025,      0.718,      0.044,     -1.116,      0.278],\n",
      "        [     0.097,      0.761,     -0.983,      0.361,      0.921,     -0.364],\n",
      "        [     0.306,     -0.105,      1.058,     -1.418,      0.986,     -3.252],\n",
      "        [    -0.112,      0.201,     -0.001,      0.111,     -1.101,     -0.760],\n",
      "        [    -0.121,     -0.129,      0.023,      0.067,     -1.803,     -2.787],\n",
      "        [    -0.115,      0.492,      0.442,      0.008,     -0.447,      0.364],\n",
      "        [     0.535,     -0.033,      0.012,      0.010,     -0.535,     -2.175],\n",
      "        [    -0.030,      0.456,     -0.030,      0.351,     -1.683,     -0.050],\n",
      "        [     0.103,      0.385,     -0.273,     -0.701,     -0.602,     -0.621],\n",
      "        [     0.640,     -0.527,     -0.043,     -1.481,      1.221,     -3.327],\n",
      "        [    -0.188,      0.233,      0.348,     -0.682,      0.319,     -0.124],\n",
      "        [    -0.138,     -0.070,      0.484,     -0.328,     -0.793,     -0.328],\n",
      "        [    -0.178,     -0.074,      0.558,     -0.305,     -0.150,     -0.329],\n",
      "        [    -0.094,      0.781,      0.439,      0.160,      0.013,      0.561],\n",
      "        [     0.000,      0.498,      0.395,     -0.191,      0.426,     -0.069],\n",
      "        [     0.063,      0.314,     -0.152,     -0.586,     -0.955,     -0.384],\n",
      "        [    -0.067,      0.495,     -0.028,      0.085,     -1.970,      0.165],\n",
      "        [     0.328,      0.618,      0.990,      0.208,     -0.962,      0.714],\n",
      "        [     0.183,      1.163,      1.105,      0.035,     -1.178,      0.563],\n",
      "        [    -0.115,      0.433,     -0.228,     -0.801,      1.794,     -0.963],\n",
      "        [    -0.008,      0.919,      0.844,     -0.088,     -1.863,      0.026],\n",
      "        [    -0.072,      0.163,      0.919,      0.304,     -1.631,      0.773],\n",
      "        [    -0.163,      0.336,      0.132,      0.034,     -1.691,      0.567],\n",
      "        [    -0.118,      0.476,      0.116,     -0.079,     -1.107,      0.952],\n",
      "        [     0.059,      1.018,     -0.052,      0.123,     -1.638,      0.579],\n",
      "        [    -0.116,      0.878,      0.668,      0.029,     -0.361,      0.795],\n",
      "        [    -0.064,      0.862,      0.507,      0.083,     -0.487,      0.665],\n",
      "        [     0.385,      0.366,      0.227,     -0.161,      0.128,     -1.177],\n",
      "        [     0.062,      0.815,      0.385,      0.035,     -1.456,      0.569],\n",
      "        [    -0.123,      0.297,      0.821,      0.099,     -1.120,      0.772],\n",
      "        [    -0.162,      0.447,      0.299,      0.056,     -0.232,      0.658],\n",
      "        [     0.770,      0.496,      0.632,     -0.699,     -0.472,     -0.633],\n",
      "        [    -0.035,      0.756,      0.647,      0.239,     -0.850,      0.809],\n",
      "        [    -0.143,      0.815,     -0.043,      0.337,     -0.008,      0.884],\n",
      "        [     0.057,      0.825,      0.123,     -0.049,     -1.558,      0.608],\n",
      "        [     0.556,      0.669,     -0.175,      0.217,      0.426,      0.580],\n",
      "        [     0.021,      0.812,      0.460,      0.272,     -0.295,      0.745],\n",
      "        [     0.324,      0.824,      0.917,      0.133,     -0.951,     -0.275],\n",
      "        [     0.037,      1.087,     -0.752,      0.362,      0.684,      0.040],\n",
      "        [     0.217,      1.158,      1.328,      0.062,      1.031,     -0.139],\n",
      "        [    -0.111,      0.682,      0.259,      0.315,      0.896,      0.758],\n",
      "        [    -0.035,      1.042,      0.784,      0.249,     -1.404,      0.307],\n",
      "        [    -0.108,      0.247,      1.293,      0.110,      1.162,      0.754],\n",
      "        [     0.300,      0.859,      0.732,      0.286,     -0.125,     -0.421],\n",
      "        [    -0.126,      0.764,      0.523,      0.190,     -1.607,      0.619],\n",
      "        [     0.086,      1.025,      0.757,      0.038,     -1.679,      0.343],\n",
      "        [    -0.113,      0.607,      0.699,     -0.419,     -0.357,     -0.308],\n",
      "        [    -0.173,      0.753,      0.648,     -0.211,      0.380,      0.576],\n",
      "        [     0.491,      0.621,      2.248,      0.092,      1.400,      0.590],\n",
      "        [     0.070,      1.206,      1.199,      0.197,     -0.990,      0.708],\n",
      "        [    -0.132,      0.662,      0.994,      0.063,     -2.074,      0.324],\n",
      "        [    -0.105,      0.534,     -0.072,     -0.430,      1.123,     -0.476],\n",
      "        [    -0.134,      0.527,      0.521,      0.370,     -1.331,      0.674],\n",
      "        [    -0.052,      0.126,      0.922,      0.296,     -1.280,      0.682],\n",
      "        [    -0.092,      0.309,      0.233,      0.200,     -1.480,      0.843],\n",
      "        [    -0.157,      0.708,      0.127,      0.022,     -0.427,      0.915],\n",
      "        [     0.110,      0.746,     -0.440,     -0.268,     -1.259,     -0.035],\n",
      "        [    -0.079,      0.740,      0.459,     -0.125,      0.542,      0.088],\n",
      "        [    -0.112,      0.646,      0.247,     -0.210,     -0.302,      0.302],\n",
      "        [     0.276,      0.311,      0.061,      0.259,      0.371,     -1.599],\n",
      "        [     0.050,      0.877,      0.353,      0.055,     -1.218,      0.677],\n",
      "        [    -0.127,      0.546,      0.840,      0.105,     -1.309,      0.840],\n",
      "        [    -0.140,      0.411,      0.547,      0.101,     -0.432,      0.784],\n",
      "        [     0.750,      0.683,      0.597,     -0.240,     -1.194,      0.103],\n",
      "        [     0.056,      0.767,      0.487,      0.224,     -0.789,      0.716],\n",
      "        [    -0.136,      0.793,     -0.106,      0.282,      0.124,      0.888],\n",
      "        [     0.183,      0.659,     -0.153,     -0.428,     -1.095,      0.156],\n",
      "        [     0.362,      0.702,     -0.190,      0.128,     -0.288,      0.594],\n",
      "        [    -0.024,      0.688,      0.473,      0.268,     -0.409,      0.693],\n",
      "        [     0.175,      0.850,      0.853,      0.294,     -1.125,      0.030],\n",
      "        [     0.238,      0.865,      0.253,      0.147,     -1.199,      0.756],\n",
      "        [    -0.109,      0.537,      0.701,      0.141,     -1.339,      0.930],\n",
      "        [    -0.071,      0.951,     -0.062,      0.026,     -1.714,      0.869],\n",
      "        [    -0.131,      0.633,      1.010,      0.130,     -1.855,      0.444],\n",
      "        [    -0.117,      0.998,      0.107,      0.530,      1.286,      0.735],\n",
      "        [    -0.162,      0.755,     -0.886,     -0.148,     -0.712,     -0.503],\n",
      "        [     0.586,      0.389,      0.906,     -1.029,      1.452,     -2.089],\n",
      "        [    -0.059,      0.981,      0.097,      0.321,      0.611,      0.548],\n",
      "        [     0.264,      1.063,      1.127,      0.208,     -0.682,      0.046],\n",
      "        [    -0.178,      0.949,      1.520,      0.161,      2.693,      0.556],\n",
      "        [     0.377,      0.893,      1.144,      0.340,     -0.788,     -0.343],\n",
      "        [    -0.117,      0.705,      1.000,      0.251,     -1.290,      0.389],\n",
      "        [     0.120,      0.963,      0.815,     -0.089,     -1.758,      0.045],\n",
      "        [     0.535,      0.491,      2.056,      0.080,      1.162,      0.654],\n",
      "        [     0.438,      1.093,      0.465,      0.149,     -0.044,      0.606],\n",
      "        [    -0.153,      0.695,      0.629,     -0.231,     -1.741,     -0.182],\n",
      "        [     0.176,      1.029,      1.439,     -0.023,     -1.277,      0.083],\n",
      "        [    -0.111,      0.157,      1.275,      0.308,     -1.116,      0.395],\n",
      "        [    -0.166,      0.403,      0.747,      0.270,     -0.031,      0.452],\n",
      "        [    -0.149,      0.492,     -0.566,     -0.091,     -1.082,      0.217],\n",
      "        [    -0.011,      1.262,      0.292,      0.344,     -0.535,      0.371],\n",
      "        [    -0.148,      0.888,      0.603,      0.747,      0.753,      0.534],\n",
      "        [    -0.119,      0.656,      0.238,      0.014,     -1.306,      0.826],\n",
      "        [    -0.027,      0.967,      0.228,      0.008,     -0.214,      0.670],\n",
      "        [     0.051,      0.847,     -0.534,     -0.112,     -1.132,      0.137],\n",
      "        [    -0.006,      0.842,      0.898,      0.160,      0.502,      0.325],\n",
      "        [    -0.158,      0.412,     -0.242,     -0.434,     -1.481,     -1.052],\n",
      "        [    -0.169,      0.494,      0.355,      0.148,      0.100,      0.266],\n",
      "        [    -0.155,      0.649,      0.475,     -0.130,     -0.304,      0.322],\n",
      "        [    -0.125,      0.495,      0.764,      0.142,     -0.708,      0.930],\n",
      "        [    -0.136,      0.922,      0.191,      0.105,     -0.376,      0.895],\n",
      "        [    -0.144,      0.769,      0.724,      0.206,     -0.424,      0.773],\n",
      "        [    -0.054,      0.765,      0.550,     -0.104,     -1.445,      0.162],\n",
      "        [     0.124,      0.381,     -0.365,     -0.171,     -1.413,     -1.045],\n",
      "        [    -0.007,      0.775,      0.254,     -0.045,     -1.850,      0.552],\n",
      "        [    -0.152,      0.591,     -0.105,      0.128,     -0.261,      0.722],\n",
      "        [    -0.204,     -0.006,      0.709,      0.604,     -0.634,     -1.026],\n",
      "        [    -0.062,      0.534,      1.493,     -0.217,     -0.455,     -0.431],\n",
      "        [     0.023,      0.881,      0.080,     -0.117,      0.368,      0.086],\n",
      "        [    -0.155,      0.469,      0.535,      0.125,     -1.105,      0.903],\n",
      "        [    -0.176,      0.704,     -0.087,      0.026,     -1.367,      0.727],\n",
      "        [    -0.169,      0.461,      0.065,      0.102,     -0.580,      0.440],\n",
      "        [     0.079,      0.936,      0.850,      0.124,     -0.361,      0.346]])\n",
      "tensor([ 3, 19,  6, 24,  0, 16,  2, 19,  0, 10,  3, 22,  2,  8,  6, 24],\n",
      "       dtype=torch.int32)\n",
      "Events: [[  13  134    0   77]\n",
      " [  12  455 1175   90]\n",
      " [  14  431    0   54]\n",
      " [  12  765  902    0]\n",
      " [   1  480 3506    0]\n",
      " [  13  706 1266   91]\n",
      " [  88  694    0    0]\n",
      " [  13  620 2909   83]\n",
      " [  12  732    0   36]\n",
      " [   1  752    0   54]\n",
      " [  13  480    0   37]\n",
      " [  12  480   62   10]\n",
      " [  12  669  813  127]\n",
      " [  13  636    0   59]\n",
      " [   0  480    0   37]\n",
      " [   0  480    0   97]\n",
      " [   1  632    4  100]\n",
      " [  12  480    0   55]\n",
      " [  12  587    0  106]\n",
      " [  12  480    0   43]\n",
      " [  12  660    0   98]\n",
      " [  13  590    0   38]\n",
      " [  88  992 1266   87]\n",
      " [  13 1160    0   98]\n",
      " [  14  960    0    0]\n",
      " [  14 1153    0   30]\n",
      " [   1 1142    0    0]\n",
      " [   1 1183    0   49]\n",
      " [  12 1440 1612    0]\n",
      " [  88 1440    0    0]\n",
      " [  13 1440    0    0]\n",
      " [  12 1440    0    0]\n",
      " [  13 1444    0  116]\n",
      " [  12 1491    0   60]\n",
      " [  13 1539    0   66]\n",
      " [   0 1485    0   85]\n",
      " [   1 1633    0    0]\n",
      " [  12 1440    0   19]\n",
      " [   0 1536    0   88]\n",
      " [  12 1569    0  115]\n",
      " [  12 1440    0   48]\n",
      " [  12 1590    0  108]\n",
      " [  12 1674  593  102]\n",
      " [  12 1476    0  101]\n",
      " [  12 1558    0  118]\n",
      " [  12 1730    0  100]\n",
      " [  89 1440  593    0]\n",
      " [  12 1533    0  108]\n",
      " [   1 1591    0  127]\n",
      " [  12 1508    0   98]\n",
      " [  12 1445    0  110]\n",
      " [  13 1482    0   35]\n",
      " [  12 2746  884    0]\n",
      " [   1 2400  946    0]\n",
      " [   0 2506    0    0]\n",
      " [   0 2464    0    0]\n",
      " [   0 2407    0   46]\n",
      " [  88 2409    0    0]\n",
      " [   0 2736    0    0]\n",
      " [   0 2400    0    0]\n",
      " [  88 2400 1171    0]\n",
      " [   0 2400  305    0]\n",
      " [   0 2400    0    0]\n",
      " [   1 2400    0    0]\n",
      " [  12 2553   12   71]\n",
      " [   0 2400  408    0]\n",
      " [   0 2400    0    0]\n",
      " [   0 2481    0   20]\n",
      " [  13 3080    0   90]\n",
      " [  13 2913    0   71]\n",
      " [   0 3360 1721    0]\n",
      " [  13 3360    0    3]\n",
      " [   1 3651    0   98]\n",
      " [   0 3392    0   72]\n",
      " [   0 3360    0  120]\n",
      " [  12 3477    0   73]\n",
      " [  13 3387    0  100]\n",
      " [  13 3439    0   84]\n",
      " [   0 3360  122    0]\n",
      " [  12 3393    0   72]\n",
      " [   1 3455    0   98]\n",
      " [   0 3413    0   83]\n",
      " [  88 3360    0    0]\n",
      " [  13 3589    0  102]\n",
      " [  12 3683    0  112]\n",
      " [  12 3360    0   77]\n",
      " [  88 3568  408   73]\n",
      " [  12 3621    0   94]\n",
      " [  13 3487    0    0]\n",
      " [  12 4667  656    5]\n",
      " [  13 4379  989    0]\n",
      " [  12 4622  859   96]\n",
      " [  13 4559    0   38]\n",
      " [   1 4425 1115   95]\n",
      " [  13 4594    0    0]\n",
      " [  13 4502    0   78]\n",
      " [  13 4356    0   43]\n",
      " [  13 4320    0    0]\n",
      " [  13 4320  364   73]\n",
      " [  14 4888 1343   74]\n",
      " [  13 4989    0   89]\n",
      " [  13 4860    0   41]\n",
      " [  12 5280 1077    0]\n",
      " [  13 5635    0   85]\n",
      " [   1 5564    0   86]\n",
      " [   0 5472    0  107]\n",
      " [  12 5301    0  116]\n",
      " [  12 5280    0    0]\n",
      " [  12 5280  519   11]\n",
      " [  12 5280    0   38]\n",
      " [   0 5528  356    0]\n",
      " [  12 5333    0   85]\n",
      " [  13 5381    0  106]\n",
      " [   1 5377    0   99]\n",
      " [  88 5280    0   13]\n",
      " [  12 5494    0   90]\n",
      " [  12 5551  119  112]\n",
      " [  12 5280    0   19]\n",
      " [  12 5402    0   75]\n",
      " [  12 5537    0   88]\n",
      " [  13 5562    0    3]\n",
      " [  12 5421    0   96]\n",
      " [  13 5415    0  118]\n",
      " [  12 5305    0  110]\n",
      " [  13 5884    0   56]\n",
      " [  12 6239 1234   93]\n",
      " [  12 6240    0    0]\n",
      " [  88 6240 1393    0]\n",
      " [  12 6548  586   69]\n",
      " [  13 6439    0    5]\n",
      " [  14 6394 2585   70]\n",
      " [  13 6566    0    0]\n",
      " [  13 6480    0   49]\n",
      " [  13 6240    0    5]\n",
      " [  88 6796 1115   83]\n",
      " [  12 6863    0   76]\n",
      " [  13 6720    0    0]\n",
      " [  13 6720    0   10]\n",
      " [   1 7015    0   50]\n",
      " [   1 6978    0   57]\n",
      " [   0 7200    0   27]\n",
      " [  12 7530    0   47]\n",
      " [  13 7679  722   67]\n",
      " [  12 7213    0  104]\n",
      " [  12 7207    0   85]\n",
      " [  12 7200    0   17]\n",
      " [  13 7353  482   41]\n",
      " [   0 7200    0    0]\n",
      " [   0 7341   96   33]\n",
      " [  12 7200    0   40]\n",
      " [   1 7336    0  118]\n",
      " [  12 7300    0  113]\n",
      " [  13 7397    0   98]\n",
      " [  13 7200    0   20]\n",
      " [   0 7200    0    0]\n",
      " [  12 7200    0   70]\n",
      " [  12 7322    0   91]\n",
      " [   1 7679    0    0]\n",
      " [  13 7200    0    0]\n",
      " [  12 7200  353   10]\n",
      " [   1 7320    0  114]\n",
      " [  12 7224    0   92]\n",
      " [   0 7297    0   55]\n",
      " [  13 7318    0   44]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n",
      "fluidsynth: error: fluid_is_soundfont(): fopen() failed: 'File does not exist.'\n",
      "Parameter '/Users/evanb/.fluidsynth/default_sound_font.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n",
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.3.0\n",
      "Copyright (C) 2000-2022 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of Creative Technology Ltd.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(run)\n",
    "ae_model = autoencoder.AutoEncoder(data_type='pon', hidden_dim=150, max_n=30)\n",
    "ae_model.load_state_dict(torch.load('/Users/evanb/Documents/Python/TimeStepMusic/models/ae_model.pt'))\n",
    "gen_model = CGAN.ConvGenerator(run.CGAN_LATENT_DIM, run.AE_LATENT_DIM)\n",
    "gen_model.load_state_dict(torch.load('/Users/evanb/Documents/Python/TimeStepMusic/models/cgan_gen_model.pt'))\n",
    "run.draw_sample(ae_model,gen_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e8d8cf45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.308, -0.083,  0.500,  ...,  0.007,  0.545, -1.211],\n",
       "        [-0.308, -0.083,  0.500,  ...,  0.007,  0.545, -1.211],\n",
       "        [-0.443, -0.242,  1.547,  ..., -0.768,  0.312,  0.516],\n",
       "        ...,\n",
       "        [-0.009, -0.087,  1.398,  ...,  1.667, -0.930,  0.176],\n",
       "        [ 1.560, -0.092,  1.176,  ...,  2.456, -0.730,  5.713],\n",
       "        [-0.010,  0.047,  1.400,  ...,  1.641, -0.929,  0.027]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "15afadcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([634, 150])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "374806aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.742)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3da5c42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.370)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ad56063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(41.875)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6a83736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-24.152)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9ec49d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-17.880, -17.722, -17.719,  ...,  29.127,  32.718,  41.875])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.view(-1).sort().values[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f680919d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdfs\n"
     ]
    }
   ],
   "source": [
    "if torch.tensor(True):\n",
    "    print('sdfs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddc4cbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005098088618957599"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/events[:,2].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "572f6e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "406e5de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9406417, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e2595b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 46, 371, 635,  52,   1], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f3e3c895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(events[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "cfb32867",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import lognorm\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.linspace(-1,2,100)\n",
    "plt.plot(x, lognorm.ppf(x, np.sqrt(sigma2), 0, np.exp(mu)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1b9135b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu=-np.log(sum(np.square(events[:,2])))/2 + 2*np.log(sum(events[:,2])) - 3*np.log(events.shape[0])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "063e1f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma2=np.log(sum(np.square(events[:,2]))) - 2*np.log(sum(events[:,2])) + np.log(events.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "33ee140c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.125998957286227, -0.022173461168885033, 84.32398063921644)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lognorm.fit(events[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "070048cf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.01600e+04, 5.76000e+02, 1.98000e+02, 2.31000e+02, 2.94000e+02,\n",
       "        3.32000e+02, 0.00000e+00, 5.12000e+02, 8.72000e+02, 2.23900e+03,\n",
       "        0.00000e+00, 4.88580e+04, 2.16991e+05, 0.00000e+00, 1.31758e+05,\n",
       "        2.63140e+04, 0.00000e+00, 5.29700e+04, 8.29380e+04, 0.00000e+00,\n",
       "        7.68780e+04, 5.23190e+04, 0.00000e+00, 5.61130e+04, 5.89100e+04,\n",
       "        0.00000e+00, 6.71580e+04, 0.00000e+00, 7.43460e+04, 7.49220e+04,\n",
       "        0.00000e+00, 8.46050e+04, 9.35790e+04, 0.00000e+00, 1.18231e+05,\n",
       "        2.09277e+05, 0.00000e+00, 2.23024e+05, 9.79930e+04, 0.00000e+00,\n",
       "        9.13380e+04, 0.00000e+00, 9.41360e+04, 8.72060e+04, 0.00000e+00,\n",
       "        9.41410e+04, 1.08754e+05, 1.28037e+05, 0.00000e+00, 1.17348e+05,\n",
       "        9.66960e+04, 0.00000e+00, 7.79220e+04, 7.78020e+04, 0.00000e+00,\n",
       "        7.90910e+04, 7.44660e+04, 1.38312e+05, 0.00000e+00, 1.37834e+05,\n",
       "        8.19410e+04, 6.68550e+04, 0.00000e+00, 6.75630e+04, 6.26120e+04,\n",
       "        6.24700e+04, 6.53810e+04, 0.00000e+00, 6.48380e+04, 6.36060e+04,\n",
       "        6.54410e+04, 6.42160e+04, 7.36320e+04, 7.33130e+04, 0.00000e+00,\n",
       "        6.21950e+04, 8.38750e+04, 9.46010e+04, 6.61590e+04, 4.93190e+04,\n",
       "        4.84440e+04, 4.70090e+04, 4.48090e+04, 4.65660e+04, 4.72890e+04,\n",
       "        4.57660e+04, 4.40890e+04, 4.30960e+04, 4.04080e+04, 4.24090e+04,\n",
       "        4.52610e+04, 5.44460e+04, 8.60390e+04, 6.31010e+04, 4.09830e+04,\n",
       "        3.86600e+04, 3.79330e+04, 3.31970e+04, 7.12450e+04, 3.46170e+04,\n",
       "        3.35670e+04, 3.19750e+04, 2.96390e+04, 6.15150e+04, 3.61320e+04,\n",
       "        5.14590e+04, 7.44270e+04, 3.12530e+04, 3.28500e+04, 6.26640e+04,\n",
       "        2.87680e+04, 2.72410e+04, 4.99990e+04, 2.27670e+04, 4.61740e+04,\n",
       "        2.58500e+04, 6.88100e+04, 2.38670e+04, 4.16110e+04, 4.08120e+04,\n",
       "        2.34720e+04, 4.91890e+04, 4.00380e+04, 1.72820e+04, 3.61120e+04,\n",
       "        5.52790e+04, 3.40860e+04, 3.13770e+04, 3.01420e+04, 3.30090e+04,\n",
       "        3.22900e+04, 3.35470e+04, 3.78490e+04, 4.03180e+04, 2.57610e+04,\n",
       "        2.41640e+04, 4.01810e+04, 2.42800e+04, 2.27880e+04, 5.10140e+04,\n",
       "        3.22740e+04, 3.28640e+04, 2.28830e+04, 3.33300e+04, 2.94490e+04,\n",
       "        4.41910e+04, 3.24020e+04, 2.15370e+04, 4.11970e+04, 2.61610e+04,\n",
       "        3.79140e+04, 2.69360e+04, 3.85770e+04, 2.90660e+04, 3.64190e+04,\n",
       "        3.71880e+04, 3.23140e+04, 3.12220e+04, 4.04210e+04, 2.98830e+04,\n",
       "        2.93890e+04, 3.35010e+04, 4.52060e+04, 3.37090e+04, 2.92710e+04,\n",
       "        3.86410e+04, 4.00440e+04, 3.51230e+04, 3.49010e+04, 3.64030e+04,\n",
       "        3.98160e+04, 3.63310e+04, 3.94670e+04, 3.60290e+04, 3.96330e+04,\n",
       "        3.72950e+04, 3.84620e+04, 4.25630e+04, 3.77360e+04, 3.81860e+04,\n",
       "        4.32030e+04, 4.20970e+04, 4.16080e+04, 4.26760e+04, 4.30110e+04,\n",
       "        4.36910e+04, 4.28410e+04, 4.59980e+04, 4.59430e+04, 4.72650e+04,\n",
       "        4.76930e+04, 5.13240e+04, 5.03270e+04, 5.12500e+04, 5.41470e+04,\n",
       "        6.02780e+04, 6.28440e+04, 7.12270e+04, 8.40630e+04, 1.34374e+05]),\n",
       " array([1.22994013e-13, 5.00000000e-03, 1.00000000e-02, 1.50000000e-02,\n",
       "        2.00000000e-02, 2.50000000e-02, 3.00000000e-02, 3.50000000e-02,\n",
       "        4.00000000e-02, 4.50000000e-02, 5.00000000e-02, 5.50000000e-02,\n",
       "        6.00000000e-02, 6.50000000e-02, 7.00000000e-02, 7.50000000e-02,\n",
       "        8.00000000e-02, 8.50000000e-02, 9.00000000e-02, 9.50000000e-02,\n",
       "        1.00000000e-01, 1.05000000e-01, 1.10000000e-01, 1.15000000e-01,\n",
       "        1.20000000e-01, 1.25000000e-01, 1.30000000e-01, 1.35000000e-01,\n",
       "        1.40000000e-01, 1.45000000e-01, 1.50000000e-01, 1.55000000e-01,\n",
       "        1.60000000e-01, 1.65000000e-01, 1.70000000e-01, 1.75000000e-01,\n",
       "        1.80000000e-01, 1.85000000e-01, 1.90000000e-01, 1.95000000e-01,\n",
       "        2.00000000e-01, 2.05000000e-01, 2.10000000e-01, 2.15000000e-01,\n",
       "        2.20000000e-01, 2.25000000e-01, 2.30000000e-01, 2.35000000e-01,\n",
       "        2.40000000e-01, 2.45000000e-01, 2.50000000e-01, 2.55000000e-01,\n",
       "        2.60000000e-01, 2.65000000e-01, 2.70000000e-01, 2.75000000e-01,\n",
       "        2.80000000e-01, 2.85000000e-01, 2.90000000e-01, 2.95000000e-01,\n",
       "        3.00000000e-01, 3.05000000e-01, 3.10000000e-01, 3.15000000e-01,\n",
       "        3.20000000e-01, 3.25000000e-01, 3.30000000e-01, 3.35000000e-01,\n",
       "        3.40000000e-01, 3.45000000e-01, 3.50000000e-01, 3.55000000e-01,\n",
       "        3.60000000e-01, 3.65000000e-01, 3.70000000e-01, 3.75000000e-01,\n",
       "        3.80000000e-01, 3.85000000e-01, 3.90000000e-01, 3.95000000e-01,\n",
       "        4.00000000e-01, 4.05000000e-01, 4.10000000e-01, 4.15000000e-01,\n",
       "        4.20000000e-01, 4.25000000e-01, 4.30000000e-01, 4.35000000e-01,\n",
       "        4.40000000e-01, 4.45000000e-01, 4.50000000e-01, 4.55000000e-01,\n",
       "        4.60000000e-01, 4.65000000e-01, 4.70000000e-01, 4.75000000e-01,\n",
       "        4.80000000e-01, 4.85000000e-01, 4.90000000e-01, 4.95000000e-01,\n",
       "        5.00000000e-01, 5.05000000e-01, 5.10000000e-01, 5.15000000e-01,\n",
       "        5.20000000e-01, 5.25000000e-01, 5.30000000e-01, 5.35000000e-01,\n",
       "        5.40000000e-01, 5.45000000e-01, 5.50000000e-01, 5.55000000e-01,\n",
       "        5.60000000e-01, 5.65000000e-01, 5.70000000e-01, 5.75000000e-01,\n",
       "        5.80000000e-01, 5.85000000e-01, 5.90000000e-01, 5.95000000e-01,\n",
       "        6.00000000e-01, 6.05000000e-01, 6.10000000e-01, 6.15000000e-01,\n",
       "        6.20000000e-01, 6.25000000e-01, 6.30000000e-01, 6.35000000e-01,\n",
       "        6.40000000e-01, 6.45000000e-01, 6.50000000e-01, 6.55000000e-01,\n",
       "        6.60000000e-01, 6.65000000e-01, 6.70000000e-01, 6.75000000e-01,\n",
       "        6.80000000e-01, 6.85000000e-01, 6.90000000e-01, 6.95000000e-01,\n",
       "        7.00000000e-01, 7.05000000e-01, 7.10000000e-01, 7.15000000e-01,\n",
       "        7.20000000e-01, 7.25000000e-01, 7.30000000e-01, 7.35000000e-01,\n",
       "        7.40000000e-01, 7.45000000e-01, 7.50000000e-01, 7.55000000e-01,\n",
       "        7.60000000e-01, 7.65000000e-01, 7.70000000e-01, 7.75000000e-01,\n",
       "        7.80000000e-01, 7.85000000e-01, 7.90000000e-01, 7.95000000e-01,\n",
       "        8.00000000e-01, 8.05000000e-01, 8.10000000e-01, 8.15000000e-01,\n",
       "        8.20000000e-01, 8.25000000e-01, 8.30000000e-01, 8.35000000e-01,\n",
       "        8.40000000e-01, 8.45000000e-01, 8.50000000e-01, 8.55000000e-01,\n",
       "        8.60000000e-01, 8.65000000e-01, 8.70000000e-01, 8.75000000e-01,\n",
       "        8.80000000e-01, 8.85000000e-01, 8.90000000e-01, 8.95000000e-01,\n",
       "        9.00000000e-01, 9.05000000e-01, 9.10000000e-01, 9.15000000e-01,\n",
       "        9.20000000e-01, 9.25000000e-01, 9.30000000e-01, 9.35000000e-01,\n",
       "        9.40000000e-01, 9.45000000e-01, 9.50000000e-01, 9.55000000e-01,\n",
       "        9.60000000e-01, 9.65000000e-01, 9.70000000e-01, 9.75000000e-01,\n",
       "        9.80000000e-01, 9.85000000e-01, 9.90000000e-01, 9.95000000e-01,\n",
       "        1.00000000e+00]),\n",
       " <BarContainer object of 200 artists>)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lognorm.cdf(events[:,2], 1.125998957286227, -0.022173461168885033, 84.32398063921644), 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "dba0f566",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_lengths = lognorm.cdf(events[:,2], 1.125998957286227, -0.022173461168885033, 84.32398063921644)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0cd0b826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1668.,  635.,   94., ...,   77.,  529.,   51.])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lognorm.ppf(norm_lengths, 1.125998957286227, -0.022173461168885033, 84.32398063921644)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2795db20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.abs(events[:,2] - lognorm.ppf(norm_lengths, 1.125998957286227, -0.022173461168885033, 84.32398063921644))<.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e70835e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9406417,)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_lengths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0549db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.77269411e-01, 1.98961596e+01, 3.26656181e+01, 4.66987387e+01,\n",
       "       6.33736332e+01, 8.43018072e+01, 1.12138774e+02, 1.52169498e+02,\n",
       "       2.17506554e+02, 3.56962204e+02, 1.78011059e+04])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import lognorm\n",
    "lognorm.ppf([0.000001, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1-.000001], 1.125998957286227, -0.022173461168885033, 84.32398063921644)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bad954d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(np.log2(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10db73d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(3, 0, -1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(3,0,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdf82750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(3,0,-1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5069b433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
